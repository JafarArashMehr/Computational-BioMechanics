

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>4. Machine Learning in Diagnosis &mdash; Jafar Arash Mehr 2022 documentation</title>
  

  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  

  
    <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  

  
        <link rel="index" title="Index"
              href="../genindex.html"/>
        <link rel="search" title="Search" href="../search.html"/>
    <link rel="top" title="Jafar Arash Mehr 2022 documentation" href="../index.html"/>
        <link rel="next" title="About the Author" href="contact.html"/>
        <link rel="prev" title="3. Inverse Finite Element (Optimization)" href="optimization.html"/> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html">
          

          
            
            <img src="../_static/profile.jpg" class="logo" />
          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <p class="caption"><span class="caption-text">Table of Contents</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="Intro.html">What is this document about?</a></li>
<li class="toctree-l1"><a class="reference internal" href="resource.html">Useful Resources</a></li>
<li class="toctree-l1"><a class="reference internal" href="package.html">Required Packages</a></li>
<li class="toctree-l1"><a class="reference internal" href="hyperelasticity.html"><strong>1. Hyperelasticity</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="multi-physics.html"><strong>2. Multi-Physics Problem</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="optimization.html"><strong>3. Inverse Finite Element (Optimization)</strong></a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#"><strong>4. Machine Learning in Diagnosis</strong></a><ul>
<li class="toctree-l2"><a class="reference internal" href="#linear-discriminant-analysis">4.1. Linear Discriminant Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="#mathematical-backend">4.2. Mathematical Backend</a></li>
<li class="toctree-l2"><a class="reference internal" href="#a-real-medical-application">4.3. A Real Medical Application</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#disease-background">4.3.1 Disease Background</a></li>
<li class="toctree-l3"><a class="reference internal" href="#python-implementation">4.3.2. Python Implementation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#prediction-of-an-unknown-case">4.3.3. Prediction of an Unknown Case</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#case-1">4.3.3.1. Case.1</a></li>
<li class="toctree-l4"><a class="reference internal" href="#case-2">4.3.3.2. Case.2</a></li>
<li class="toctree-l4"><a class="reference internal" href="#case-3">4.3.3.3. Case.3</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="contact.html">About the Author</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../index.html">Jafar Arash Mehr</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          

 



<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../index.html">Docs</a> &raquo;</li>
      
    <li><strong>4. Machine Learning in Diagnosis</strong></li>
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/rst/machine-learning.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="machine-learning-in-diagnosis">
<h1><strong>4. Machine Learning in Diagnosis</strong><a class="headerlink" href="#machine-learning-in-diagnosis" title="Permalink to this headline">¶</a></h1>
<div class="section" id="linear-discriminant-analysis">
<h2>4.1. Linear Discriminant Analysis<a class="headerlink" href="#linear-discriminant-analysis" title="Permalink to this headline">¶</a></h2>
<p>Machine Learning (ML) is a branch of artificial intelligence that employs a wide range of techniques and tools which are helpful in diagnostic applications in a variety of medical areas like
diagnosis and detection of diseases. These methods are being used in a variety of applications inorder to identify, classify and detect different diseases ranging from cancer and Alzheimer
to ophthalmology. Linear Discriminant Analysis is a supervised classification technique in machine learning for
dimensionality reduction applications. In this method we seek to reduce the dimensions by taking off the unimportant and redundant features by transforming the features from higher dimensional
space to a lower dimensional space where the data achieves maximum class separability</p>
</div>
<div class="section" id="mathematical-backend">
<h2>4.2. Mathematical Backend<a class="headerlink" href="#mathematical-backend" title="Permalink to this headline">¶</a></h2>
<p>In the LDA, the derived features are linear combinations of the original features. For implementation we can start off by calculating two matrixes including within-class <span class="math notranslate nohighlight">\(S_W\)</span>. The <span class="math notranslate nohighlight">\(S_W\)</span> and <span class="math notranslate nohighlight">\(S_B\)</span> are two <span class="math notranslate nohighlight">\(n \times n\)</span> matrixes indicating the number of features in the data where <span class="math notranslate nohighlight">\(n\)</span> is the number of the features.
The <span class="math notranslate nohighlight">\(S_W\)</span> corresponds to the separability between different classes (i.e. the distance between the mean of different classes). The optimal transformation in classical LDA is achieved by minimizing the <span class="math notranslate nohighlight">\(S_W\)</span> distance and maximizing the <span class="math notranslate nohighlight">\(S_B\)</span> distance simultaneously, leading to maximum discrimination. The <span class="math notranslate nohighlight">\(S_W\)</span> is represented as following:</p>
<div class="math notranslate nohighlight" id="eq-100">
<span id="equation-eq-100"></span><span class="eqno">(100)<a class="headerlink" href="#eq-100" title="Permalink to this equation">¶</a></span>\[ S_W=  \sum_{i_=1}^{class} S_i \quad Where \quad  S_i = \sum_{j_=1}^{n} (x_j-m_i)(x_j-m_i)^T\]</div>
<p>In the above equations, the class represent the classes (e.g. Normal, Low-Flattened and High-Flattened globes). <span class="math notranslate nohighlight">\(X\)</span> is
the number of the samples including the features in each class. The <span class="math notranslate nohighlight">\(m\)</span> is a vector including the mean of each feature in each class:</p>
<div class="math notranslate nohighlight" id="eq-101">
<span id="equation-eq-101"></span><span class="eqno">(101)<a class="headerlink" href="#eq-101" title="Permalink to this equation">¶</a></span>\[ m_i= \frac {1}{n_i} \sum_{k=1}{n} X_k\]</div>
<p>The <span class="math notranslate nohighlight">\(S_B\)</span> is computed as following:</p>
<div class="math notranslate nohighlight" id="eq-102">
<span id="equation-eq-102"></span><span class="eqno">(102)<a class="headerlink" href="#eq-102" title="Permalink to this equation">¶</a></span>\[ S_B= \sum_{I=1}^{c} N_i(m_i-\mu)(m_i-\mu)^T\]</div>
<p>Where <span class="math notranslate nohighlight">\(\mu\)</span> is a vector containing the mean of all the samples in all of the classes. In the LDA analysis we try to obtain the lower dimensional space in a way that it maximizes the between class variance and minimizes the within class variance. We can transform data using a transformation matrix <span class="math notranslate nohighlight">\(\xi\)</span> .With that being said, the transformed dataset (Y), could be written as:</p>
<div class="math notranslate nohighlight" id="eq-103">
<span id="equation-eq-103"></span><span class="eqno">(103)<a class="headerlink" href="#eq-103" title="Permalink to this equation">¶</a></span>\[ Y = \xi^T \times X\]</div>
<p>In order to obtain a good separation between classes we seek to maximize the <span class="math notranslate nohighlight">\(\frac{S_B}{S_W}\)</span>. By applying this transformation to <span class="math notranslate nohighlight">\(S_B\)</span> and <span class="math notranslate nohighlight">\(S_W\)</span> :</p>
<div class="math notranslate nohighlight" id="eq-104">
<span id="equation-eq-104"></span><span class="eqno">(104)<a class="headerlink" href="#eq-104" title="Permalink to this equation">¶</a></span>\[ S_W= \sum_{I=I}^{class} \sum_{j=1}^{class} [(\xi^T(x_j-m_i)(\xi^T(x_j-m_i))^T]_i=\xi^T S_W \xi\]</div>
<div class="math notranslate nohighlight" id="eq-105">
<span id="equation-eq-105"></span><span class="eqno">(105)<a class="headerlink" href="#eq-105" title="Permalink to this equation">¶</a></span>\[ S_B= \sum_{I=I}^{class} N_i [(\xi^T(m_i-m)(\xi^T(m_i-m))^T]=\xi^T S_B \xi\]</div>
<p>Then the equation  becomes  <span class="math notranslate nohighlight">\(\frac{\xi^T S_B \xi}{\xi^T S_W \xi}\)</span>. Now we can find the <span class="math notranslate nohighlight">\(\xi\)</span> that maximizes this equation. It turns out that <span class="math notranslate nohighlight">\(\xi\)</span> can be found by calculating the Eigenvectors of <span class="math notranslate nohighlight">\({S_W}^{-1} S_B\)</span>.
In other words, we can look at it as a constrained optimization problem with <span class="math notranslate nohighlight">\(\xi^T S_W \xi = P\)</span>.To this end, we can rewrite this in Lagrangian form:</p>
<div class="math notranslate nohighlight" id="eq-106">
<span id="equation-eq-106"></span><span class="eqno">(106)<a class="headerlink" href="#eq-106" title="Permalink to this equation">¶</a></span>\[ L=\xi^T S_B \xi - \lambda (\xi^T S_W \xi - P)\]</div>
<p>Then we can take the derivative of the above equation and set it equal to zero:</p>
<div class="math notranslate nohighlight" id="eq-107">
<span id="equation-eq-107"></span><span class="eqno">(107)<a class="headerlink" href="#eq-107" title="Permalink to this equation">¶</a></span>\[ \frac{\partial L}{\partial \xi} = 2(S_B-\lambda S_W) \xi = 0\]</div>
<p>Which gives:</p>
<div class="math notranslate nohighlight" id="eq-108">
<span id="equation-eq-108"></span><span class="eqno">(108)<a class="headerlink" href="#eq-108" title="Permalink to this equation">¶</a></span>\[ S_B \xi = \lambda S_W \xi\]</div>
<p>The above generalized eigenvalue problem can be written as following:</p>
<div class="math notranslate nohighlight" id="eq-109">
<span id="equation-eq-109"></span><span class="eqno">(109)<a class="headerlink" href="#eq-109" title="Permalink to this equation">¶</a></span>\[ {S_W}^{-1} S_B \xi = \lambda \xi\]</div>
<div class="math notranslate nohighlight" id="eq-110">
<span id="equation-eq-110"></span><span class="eqno">(110)<a class="headerlink" href="#eq-110" title="Permalink to this equation">¶</a></span>\[ {S_W}^{-1} S_B \xi - \lambda \xi = 0 \Rightarrow {S_W}^{-1} S_B \xi - \lambda I \xi = 0\]</div>
<p>The above equation could be written as following:</p>
<div class="math notranslate nohighlight" id="eq-111">
<span id="equation-eq-111"></span><span class="eqno">(111)<a class="headerlink" href="#eq-111" title="Permalink to this equation">¶</a></span>\[ ({S_W}^{-1} S_B - \lambda I) \xi = 0\]</div>
<p>Solving this equation gives us the eigenvalues (<span class="math notranslate nohighlight">\(\lambda_i\)</span>) and corresponding eigenvectors of the <span class="math notranslate nohighlight">\(S_W^{-1} S_B\)</span>
matrix.</p>
</div>
<div class="section" id="a-real-medical-application">
<h2>4.3. A Real Medical Application<a class="headerlink" href="#a-real-medical-application" title="Permalink to this headline">¶</a></h2>
<div class="section" id="disease-background">
<h3>4.3.1 Disease Background<a class="headerlink" href="#disease-background" title="Permalink to this headline">¶</a></h3>
<p>In this section, we use the LDA in a real world application in order to detect an eye-related disease. This eye disorder is called Idiopathic intracranial hypertension (IIH). The IIH occurs most frequently among obese women and astronauts coming back from long-duration space mission. The most common symptoms of this disease include daily and persistent headache , transient visual obscuration and nausea.
Flattening of the posterior eye globe in the magnetic resonance (MR) images is known as one of the most important signs in the patients diagnosed with IIH.
In this regards, mechanical factors have been proposed for such phenomenon. These mechanical factors include the material properties of the tissue within the optic nerve head and also the pressure loads like ICP and intraocular pressure (IOP). This eye disease has also been studied using numerical model based on finite element method:</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>Here is the reference:</p>
<blockquote class="last">
<div><a class="reference external" href="https://www.mdpi.com/2075-1729/10/12/316">Numerical Investigation on the Role of Mechanical Factors Contributing to Globe Flattening in States of Elevated Intracranial Pressure</a></div></blockquote>
</div>
<p>In general, the degree of flattening of the posterior of the eye globe could represent the severity of this disease. To be more specific, the higher the flattening, the more severe the disease.
The eye globe could be modeled as an axisymetric finite element model where the flattening of the posterior of the globe is represented by <span class="math notranslate nohighlight">\(\alpha\)</span> and <span class="math notranslate nohighlight">\(\beta\)</span>. we introduce a new parameter and call it Cut-Off angle (<span class="math notranslate nohighlight">\(\beta\)</span>) as an angle (<span class="math notranslate nohighlight">\(\theta\)</span>) in which the slopes (<span class="math notranslate nohighlight">\(\alpha\)</span>) up to the
<span class="math notranslate nohighlight">\(\beta\)</span> are fairly small (−0.5° ≤ <span class="math notranslate nohighlight">\(\alpha\)</span> ≤ 0.5°). The simplified eye model consisted of different tissues including Sclera (SC), Peripapillary Sclera (PSC), Dura Mater (DM), Retina (RET), Vessel (VES), Lamina Cribrosa (LC), Pia Mater (PM) and Optic Nerve (ON). These parameters are all shown in next figure:</p>
<div class="figure align-center" id="id1">
<img alt="../_images/14.png" src="../_images/14.png" />
<p class="caption"><span class="caption-number">Fig. 14 </span><span class="caption-text">Illustration of the parameters <span class="math notranslate nohighlight">\(\alpha\)</span> , <span class="math notranslate nohighlight">\(\beta\)</span> and <span class="math notranslate nohighlight">\(\theta\)</span>. The tissues within the eye globe are shown in the left.</span><a class="headerlink" href="#id1" title="Permalink to this image">¶</a></p>
</div>
<p>In general, the lower value of <span class="math notranslate nohighlight">\(\beta\)</span> indicates larger flattening area at the posterior of the eye globe that is equal to higher severity of this eye disease.
For a normal eye where there is no flattening at the back of the globe, the <span class="math notranslate nohighlight">\(\beta=90°\)</span>. For an eye globe where the area of flattening is relatively small, the <span class="math notranslate nohighlight">\(\beta=80°\)</span>. Finally the eye globe with largest degree of globe flattening is the eye with the <span class="math notranslate nohighlight">\(\beta=70°\)</span>.</p>
</div>
<div class="section" id="python-implementation">
<h3>4.3.2. Python Implementation<a class="headerlink" href="#python-implementation" title="Permalink to this headline">¶</a></h3>
<p>According to these 3 classes, we are given 1211 eye globes including 360 normal eye globe, 550 eye globes with low globe flattening and 301 eye globe with high globe flattening. The different classes are shown in this table:</p>
<table border="1" class="docutils" id="tab-3">
<caption><span class="caption-number">Table 3 </span><span class="caption-text">The criteria defining different levels of globe flattening</span><a class="headerlink" href="#tab-3" title="Permalink to this table">¶</a></caption>
<colgroup>
<col width="37%" />
<col width="26%" />
<col width="37%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td>Class Description</td>
<td><span class="math notranslate nohighlight">\(\beta\)</span> (Degrees)</td>
<td>Number of eye globe</td>
</tr>
<tr class="row-even"><td>Normal Globe</td>
<td>90</td>
<td>360</td>
</tr>
<tr class="row-odd"><td>Low - Flattened Globe</td>
<td>80</td>
<td>550</td>
</tr>
<tr class="row-even"><td>High - Flattened Globe</td>
<td>70</td>
<td>301</td>
</tr>
</tbody>
</table>
<p>From the mechanical point of view, we have 9 different mechanical features playing role in the deformation of the eye globe two of which are internal pressures including the IOP and ICP. The remaining 7 features are the material properties of the constitutive tissues as shown previously.
If want to visualize our classes, this is not feasible to do it on a 9 dimensionals space. Instead, we take advantage of LDA in order to project the results on a 2 dimensional space where the classes are separated from each other.
Regarding the given eye globes, we have information of the pressures  (IOP and ICP) as well as estimation of the material properties of the all tissues inside each globe.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">All values should be used after normalization meaning that for each feature, all data should be divided by the maximum value in the corresponding feature. With that being said, all data are values between 0 and 1. We should write all data in a text file. Each line in the text file correspond to 1 eye globe that has 9 numbers which are the normalized values of the features for that particular eye separated by “,” and the last item in the line is the name of the class that the eye globe belongs to. It should be either “A” or “B” or “C” corresponding to the “High Flattened”, “Low Flattened” and “Normal” eye globes.</p>
</div>
<p>Here is an example of one line in the text file for an eye globe belonging to the high-flattened class:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span class="mf">0.25</span><span class="p">,</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.2</span><span class="p">,</span><span class="mf">0.04</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mf">0.1111111111</span><span class="p">,</span><span class="mf">0.1111111111</span><span class="p">,</span><span class="mf">0.6665</span><span class="p">,</span><span class="mf">0.33325</span><span class="p">,</span><span class="n">A</span>
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The name of the text file is : <strong>LARGE-NORMALIZED.txt</strong> including 1211 lines and is available in the github repository in the folder <strong>EYE-MODELS</strong></p>
</div>
<p>Here is the Python implementation of the LDA analysis on the given data. We use <strong>Panda</strong> and <strong>Scikitlearn</strong> for reading and preprocessing of the data including the features and classes. In the meantime, we use <strong>Numpy</strong> for mathematical implementation of the LDA analysis:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="c1"># Here we should define all 9 features including 9 material properties and 2 pressures</span>
<span class="n">feature_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span><span class="n">label</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">label</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
                <span class="nb">range</span><span class="p">(</span><span class="mi">9</span><span class="p">),(</span><span class="s1">&#39;SC&#39;</span><span class="p">,</span><span class="s1">&#39;PSC&#39;</span><span class="p">,</span><span class="s1">&#39;PIA&#39;</span><span class="p">,</span><span class="s1">&#39;DURA&#39;</span><span class="p">,</span><span class="s1">&#39;LC&#39;</span><span class="p">,</span><span class="s1">&#39;RET&#39;</span><span class="p">,</span><span class="s1">&#39;ON&#39;</span><span class="p">,</span><span class="s1">&#39;IOP&#39;</span><span class="p">,</span><span class="s1">&#39;ICP&#39;</span><span class="p">))}</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;LARGE-NORMALIZED.txt&#39;</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">l</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">l</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">feature_dict</span><span class="o">.</span><span class="n">items</span><span class="p">())]</span> <span class="o">+</span> <span class="p">[</span><span class="s1">&#39;class label&#39;</span><span class="p">]</span>
<span class="n">df</span><span class="o">.</span><span class="n">tail</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">ix</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="mi">9</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">ix</span><span class="p">[:,</span><span class="mi">9</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">label_dict</span> <span class="o">=</span> <span class="p">{</span><span class="mi">1</span><span class="p">:</span> <span class="s1">&#39;High-Flattened&#39;</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span> <span class="s1">&#39;Low-Flattened&#39;</span><span class="p">,</span> <span class="mi">3</span><span class="p">:</span><span class="s1">&#39;Normal&#39;</span><span class="p">}</span>

<span class="n">enc</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">label_encoder</span> <span class="o">=</span> <span class="n">enc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">label_encoder</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>

<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

<span class="n">mean_vectors</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">cl</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">):</span>
    <span class="n">mean_vectors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="n">cl</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>

<span class="c1"># S_W is 9x9 matrix</span>
<span class="n">S_W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">9</span><span class="p">,</span><span class="mi">9</span><span class="p">))</span>
<span class="k">for</span> <span class="n">cl</span><span class="p">,</span><span class="n">mv</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span> <span class="n">mean_vectors</span><span class="p">):</span>
    <span class="n">class_sc_mat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">9</span><span class="p">,</span><span class="mi">9</span><span class="p">))</span>                  <span class="c1"># scatter matrix for every class</span>
    <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">X</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="n">cl</span><span class="p">]:</span>
        <span class="n">row</span><span class="p">,</span> <span class="n">mv</span> <span class="o">=</span> <span class="n">row</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">mv</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># make column vectors</span>
        <span class="n">class_sc_mat</span> <span class="o">+=</span> <span class="p">(</span><span class="n">row</span><span class="o">-</span><span class="n">mv</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">((</span><span class="n">row</span><span class="o">-</span><span class="n">mv</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">S_W</span> <span class="o">+=</span> <span class="n">class_sc_mat</span>                             <span class="c1"># sum class scatter matrices</span>

<span class="n">overall_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># S_B is 9x9 matrix</span>
<span class="n">S_B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">9</span><span class="p">,</span><span class="mi">9</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">mean_vec</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">mean_vectors</span><span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,:]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">mean_vec</span> <span class="o">=</span> <span class="n">mean_vec</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># make column vector</span>
    <span class="n">overall_mean</span> <span class="o">=</span> <span class="n">overall_mean</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># make column vector</span>
    <span class="n">S_B</span> <span class="o">+=</span> <span class="n">n</span> <span class="o">*</span> <span class="p">(</span><span class="n">mean_vec</span> <span class="o">-</span> <span class="n">overall_mean</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">((</span><span class="n">mean_vec</span> <span class="o">-</span> <span class="n">overall_mean</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

<span class="n">eig_vals</span><span class="p">,</span> <span class="n">eig_vecs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eig</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">S_W</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">S_B</span><span class="p">))</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">eig_vals</span><span class="p">)):</span>
    <span class="n">eigvec_sc</span> <span class="o">=</span> <span class="n">eig_vecs</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>

<span class="n">eig_pairs</span> <span class="o">=</span> <span class="p">[(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">eig_vals</span><span class="p">[</span><span class="n">i</span><span class="p">]),</span> <span class="n">eig_vecs</span><span class="p">[:,</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">eig_vals</span><span class="p">))]</span>

<span class="c1"># Sort the (eigenvalue, eigenvector) tuples from high to low</span>
<span class="n">eig_pairs</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">eig_pairs</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">k</span><span class="p">:</span> <span class="n">k</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Variance explained:</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">eigv_sum</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">eig_vals</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">j</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">eig_pairs</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;eigenvalue {0:}: {1:.2%}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="n">j</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="n">eigv_sum</span><span class="p">)</span><span class="o">.</span><span class="n">real</span><span class="p">))</span>

<span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">eig_pairs</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">eig_pairs</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">1</span><span class="p">)))</span>
<span class="n">X_lda</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W</span><span class="p">)</span>

<span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="s1">&#39;seaborn-whitegrid&#39;</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">label</span><span class="p">,</span> <span class="n">marker</span><span class="p">,</span> <span class="n">color</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;^&#39;</span><span class="p">,</span> <span class="s1">&#39;s&#39;</span><span class="p">,</span> <span class="s1">&#39;o&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span><span class="s1">&#39;g&#39;</span><span class="p">)):</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_lda</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">real</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="n">label</span><span class="p">],</span>
                    <span class="n">y</span><span class="o">=</span><span class="n">X_lda</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">real</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="n">label</span><span class="p">],</span>
                    <span class="n">marker</span><span class="o">=</span><span class="n">marker</span><span class="p">,</span>
                    <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span>
                    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                    <span class="n">label</span><span class="o">=</span><span class="n">label_dict</span><span class="p">[</span><span class="n">label</span><span class="p">])</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;LDA 1&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">25</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;LDA 2&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">25</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mf">1.0</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">&#39;major&#39;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;lower right&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;Results.png&#39;</span><span class="p">,</span> <span class="n">format</span><span class="o">=</span><span class="s1">&#39;png&#39;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">1200</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p>Here is the output of the code:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span class="n">Variance</span> <span class="n">explained</span><span class="p">:</span>

                <span class="n">eigenvalue</span> <span class="mi">1</span><span class="p">:</span> <span class="mf">80.74</span><span class="o">%</span>
                <span class="n">eigenvalue</span> <span class="mi">2</span><span class="p">:</span> <span class="mf">19.26</span><span class="o">%</span>
                <span class="n">eigenvalue</span> <span class="mi">3</span><span class="p">:</span> <span class="mf">0.00</span><span class="o">%</span>
                <span class="n">eigenvalue</span> <span class="mi">4</span><span class="p">:</span> <span class="mf">0.00</span><span class="o">%</span>
                <span class="n">eigenvalue</span> <span class="mi">5</span><span class="p">:</span> <span class="mf">0.00</span><span class="o">%</span>
                <span class="n">eigenvalue</span> <span class="mi">6</span><span class="p">:</span> <span class="mf">0.00</span><span class="o">%</span>
                <span class="n">eigenvalue</span> <span class="mi">7</span><span class="p">:</span> <span class="mf">0.00</span><span class="o">%</span>
                <span class="n">eigenvalue</span> <span class="mi">8</span><span class="p">:</span> <span class="mf">0.00</span><span class="o">%</span>
                <span class="n">eigenvalue</span> <span class="mi">9</span><span class="p">:</span> <span class="mf">0.00</span><span class="o">%</span>
</pre></div>
</div>
<p>The above shows the sorted Variance explained where it is has become zero in 7 directions and only 2 directions have remained (LDA1 &amp; LDA2) where the variance explained are largest.</p>
<p>In the below figure, we can see how the classes have been projected on the 2D space and separated from each other:</p>
<div class="figure align-center" id="id2">
<img alt="../_images/15.png" src="../_images/15.png" />
<p class="caption"><span class="caption-number">Fig. 15 </span><span class="caption-text">Separation of the classes including the Normal eyes, Lowe-Flattened eyes and High-Flattened eyes after implementation of the LDA analysis on the data.</span><a class="headerlink" href="#id2" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="prediction-of-an-unknown-case">
<h3>4.3.3. Prediction of an Unknown Case<a class="headerlink" href="#prediction-of-an-unknown-case" title="Permalink to this headline">¶</a></h3>
<p>Now, lets say how we can use the LDA as a supervised machine learning technique to make prediction on an eye globe where we do not know which class it belongs to. We have the information about the values of the features including the material properties and also the pressures for that eye globe.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">We do not know how deformation in an eye globe with these features coulde be. In addition, we do not have any MR image of this particular eye globe to figure out if this is a normal, low flattened  or high flattened eye globe.</p>
</div>
<p>We should normalize the given data from this unknown case and then add a new line to the text file with a new class name like <strong>D</strong> corresponding to the unknown class. With that being said, after adding the new line, we need to implement some minor changes in the body of the previous code to visualize the location of the new data (e.g., Unknown Case):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="c1"># Here we should define all 9 features including 9 material properties and 2 pressures</span>
<span class="n">feature_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span><span class="n">label</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">label</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
                <span class="nb">range</span><span class="p">(</span><span class="mi">9</span><span class="p">),(</span><span class="s1">&#39;SC&#39;</span><span class="p">,</span><span class="s1">&#39;PSC&#39;</span><span class="p">,</span><span class="s1">&#39;PIA&#39;</span><span class="p">,</span><span class="s1">&#39;DURA&#39;</span><span class="p">,</span><span class="s1">&#39;LC&#39;</span><span class="p">,</span><span class="s1">&#39;RET&#39;</span><span class="p">,</span><span class="s1">&#39;ON&#39;</span><span class="p">,</span><span class="s1">&#39;IOP&#39;</span><span class="p">,</span><span class="s1">&#39;ICP&#39;</span><span class="p">))}</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;LARGE-NORMALIZED.txt&#39;</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">l</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">l</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">feature_dict</span><span class="o">.</span><span class="n">items</span><span class="p">())]</span> <span class="o">+</span> <span class="p">[</span><span class="s1">&#39;class label&#39;</span><span class="p">]</span>
<span class="n">df</span><span class="o">.</span><span class="n">tail</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">ix</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="mi">9</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">ix</span><span class="p">[:,</span><span class="mi">9</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">label_dict</span> <span class="o">=</span> <span class="p">{</span><span class="mi">1</span><span class="p">:</span> <span class="s1">&#39;High-Flattened&#39;</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span> <span class="s1">&#39;Low-Flattened&#39;</span><span class="p">,</span> <span class="mi">3</span><span class="p">:</span><span class="s1">&#39;Normal&#39;</span><span class="p">,</span><span class="mi">4</span><span class="p">:</span> <span class="s1">&#39;Unknown Class&#39;</span><span class="p">}</span>

<span class="n">enc</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">label_encoder</span> <span class="o">=</span> <span class="n">enc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">label_encoder</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>

<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

<span class="n">mean_vectors</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">cl</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">):</span>
    <span class="n">mean_vectors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="n">cl</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>

<span class="c1"># S_W is 9x9 matrix</span>
<span class="n">S_W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">9</span><span class="p">,</span><span class="mi">9</span><span class="p">))</span>
<span class="k">for</span> <span class="n">cl</span><span class="p">,</span><span class="n">mv</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> <span class="n">mean_vectors</span><span class="p">):</span>
    <span class="n">class_sc_mat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">9</span><span class="p">,</span><span class="mi">9</span><span class="p">))</span>                  <span class="c1"># scatter matrix for every class</span>
    <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">X</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="n">cl</span><span class="p">]:</span>
        <span class="n">row</span><span class="p">,</span> <span class="n">mv</span> <span class="o">=</span> <span class="n">row</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">mv</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># make column vectors</span>
        <span class="n">class_sc_mat</span> <span class="o">+=</span> <span class="p">(</span><span class="n">row</span><span class="o">-</span><span class="n">mv</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">((</span><span class="n">row</span><span class="o">-</span><span class="n">mv</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">S_W</span> <span class="o">+=</span> <span class="n">class_sc_mat</span>                             <span class="c1"># sum class scatter matrices</span>

<span class="n">overall_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># S_B is 9x9 matrix</span>
<span class="n">S_B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">9</span><span class="p">,</span><span class="mi">9</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">mean_vec</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">mean_vectors</span><span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,:]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">mean_vec</span> <span class="o">=</span> <span class="n">mean_vec</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># make column vector</span>
    <span class="n">overall_mean</span> <span class="o">=</span> <span class="n">overall_mean</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># make column vector</span>
    <span class="n">S_B</span> <span class="o">+=</span> <span class="n">n</span> <span class="o">*</span> <span class="p">(</span><span class="n">mean_vec</span> <span class="o">-</span> <span class="n">overall_mean</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">((</span><span class="n">mean_vec</span> <span class="o">-</span> <span class="n">overall_mean</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

<span class="n">eig_vals</span><span class="p">,</span> <span class="n">eig_vecs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eig</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">S_W</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">S_B</span><span class="p">))</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">eig_vals</span><span class="p">)):</span>
    <span class="n">eigvec_sc</span> <span class="o">=</span> <span class="n">eig_vecs</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>

<span class="n">eig_pairs</span> <span class="o">=</span> <span class="p">[(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">eig_vals</span><span class="p">[</span><span class="n">i</span><span class="p">]),</span> <span class="n">eig_vecs</span><span class="p">[:,</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">eig_vals</span><span class="p">))]</span>

<span class="c1"># Sort the (eigenvalue, eigenvector) tuples from high to low</span>
<span class="n">eig_pairs</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">eig_pairs</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">k</span><span class="p">:</span> <span class="n">k</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Variance explained:</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">eigv_sum</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">eig_vals</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">j</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">eig_pairs</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;eigenvalue {0:}: {1:.2%}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="n">j</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="n">eigv_sum</span><span class="p">)</span><span class="o">.</span><span class="n">real</span><span class="p">))</span>

<span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">eig_pairs</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">eig_pairs</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">1</span><span class="p">)))</span>
<span class="n">X_lda</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W</span><span class="p">)</span>

<span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="s1">&#39;seaborn-whitegrid&#39;</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">label</span><span class="p">,</span> <span class="n">marker</span><span class="p">,</span> <span class="n">color</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;^&#39;</span><span class="p">,</span> <span class="s1">&#39;s&#39;</span><span class="p">,</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span><span class="s1">&#39;*&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span><span class="s1">&#39;g&#39;</span><span class="p">,</span><span class="s1">&#39;k&#39;</span><span class="p">)):</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_lda</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">real</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="n">label</span><span class="p">],</span>
                    <span class="n">y</span><span class="o">=</span><span class="n">X_lda</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">real</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="n">label</span><span class="p">],</span>
                    <span class="n">marker</span><span class="o">=</span><span class="n">marker</span><span class="p">,</span>
                    <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span>
                    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                    <span class="n">label</span><span class="o">=</span><span class="n">label_dict</span><span class="p">[</span><span class="n">label</span><span class="p">])</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;LDA 1&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">25</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;LDA 2&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">25</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mf">1.0</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">&#39;major&#39;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;lower right&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;Results.png&#39;</span><span class="p">,</span> <span class="n">format</span><span class="o">=</span><span class="s1">&#39;png&#39;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">1200</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p>The new unknow data will be shown on the space as a black ★. This way we can see inside which class the new data will fall in.</p>
<div class="section" id="case-1">
<h4>4.3.3.1. Case.1<a class="headerlink" href="#case-1" title="Permalink to this headline">¶</a></h4>
<p>Here is the information regarding the first unknow case that should be added as a line to the data (<strong>LARGE-NORMALIZED.txt</strong>). Here is the line:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span class="mf">0.05</span><span class="p">,</span><span class="mf">0.25</span><span class="p">,</span><span class="mf">0.2</span><span class="p">,</span><span class="mf">0.2</span><span class="p">,</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mf">0.3333333333</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mf">0.33325</span><span class="p">,</span><span class="n">D</span>
</pre></div>
</div>
<p>We can visualize where the data is located in this figure:</p>
<div class="figure align-center" id="id3">
<img alt="../_images/16.png" src="../_images/16.png" />
<p class="caption"><span class="caption-number">Fig. 16 </span><span class="caption-text">Illustration of the new data. The arrow points at the location where the data is located</span><a class="headerlink" href="#id3" title="Permalink to this image">¶</a></p>
</div>
<p>It could be clearly seen that this case belongs to the high-flattened class.</p>
</div>
<div class="section" id="case-2">
<h4>4.3.3.2. Case.2<a class="headerlink" href="#case-2" title="Permalink to this headline">¶</a></h4>
<p>Here is the information regarding the second unknown case that should be added as a line to the data (<strong>LARGE-NORMALIZED.txt</strong>). Here is the line:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.04</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mf">0.3333333333</span><span class="p">,</span><span class="mf">0.1111111111</span><span class="p">,</span><span class="mf">0.33325</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">D</span>
</pre></div>
</div>
<p>We can visualize where the second unknown data is located in this figure:</p>
<div class="figure align-center" id="id4">
<img alt="../_images/17.png" src="../_images/17.png" />
<p class="caption"><span class="caption-number">Fig. 17 </span><span class="caption-text">Illustration of the second unknown data. The arrow points at the location where the data is located</span><a class="headerlink" href="#id4" title="Permalink to this image">¶</a></p>
</div>
<p>It is obvious that this case belongs to the low-flattened class.</p>
</div>
<div class="section" id="case-3">
<h4>4.3.3.3. Case.3<a class="headerlink" href="#case-3" title="Permalink to this headline">¶</a></h4>
<p>Here is the information regarding the third unknow case that should be added as a line to the data (<strong>LARGE-NORMALIZED.txt</strong>). Here is the line:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span class="mi">1</span><span class="p">,</span><span class="mf">0.11</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mf">0.03</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mf">0.22</span><span class="p">,</span><span class="mf">0.3333333333</span><span class="p">,</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.11</span><span class="p">,</span><span class="n">D</span>
</pre></div>
</div>
<p>We can visualize where the third unknown data is located in this figure:</p>
<div class="figure align-center" id="id5">
<img alt="../_images/18.png" src="../_images/18.png" />
<p class="caption"><span class="caption-number">Fig. 18 </span><span class="caption-text">Illustration of the third unknown data. The arrow points at the location where the data is located</span><a class="headerlink" href="#id5" title="Permalink to this image">¶</a></p>
</div>
<p>This case, clearly falls within the normal class.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The accuracy of the prediction of the LDA analysis to determine the class that they belong to could are verified after doing the FEM simulation based on the defined criteria defined in <a class="reference internal" href="#tab-3"><span class="std std-ref">Table.3</span></a></p>
</div>
</div>
</div>
</div>
</div>


           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="contact.html" class="btn btn-neutral float-right" title="About the Author" accesskey="n">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="optimization.html" class="btn btn-neutral" title="3. Inverse Finite Element (Optimization)" accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2022, Jafar Arash Mehr.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'2022',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>