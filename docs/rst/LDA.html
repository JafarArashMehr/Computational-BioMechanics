<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>8. Machine Learning in Diagnosis &mdash; Jafar Arash Mehr 2022 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="About the Author" href="contact.html" />
    <link rel="prev" title="7. Fundamentals of Machine Learning" href="ML.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html">
            <img src="../_static/profile.jpg" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="Intro.html"><strong>What is this document about?</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="resource.html">Useful Resources</a></li>
<li class="toctree-l1"><a class="reference internal" href="package.html">Required Packages</a></li>
<li class="toctree-l1"><a class="reference internal" href="hyperelasticity.html"><strong>1. Hyperelasticity</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="multi-physics.html"><strong>2. Multi-Physics Problem</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="drug-delivery.html"><strong>3. Drug Delivery</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="optimization.html"><strong>4. Inverse Finite Element (Optimization)</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="Statistical%20Analysis.html"><strong>5. Statistical Analysis</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="Linear%20Regression.html"><strong>6. Linear Regression</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="ML.html"><strong>7. Fundamentals of Machine Learning</strong></a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#"><strong>8. Machine Learning in Diagnosis</strong></a><ul>
<li class="toctree-l2"><a class="reference internal" href="#linear-discriminant-analysis">8.1. Linear Discriminant Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="#mathematical-background">8.2. Mathematical Background</a></li>
<li class="toctree-l2"><a class="reference internal" href="#a-real-medical-application">8.3. A Real Medical Application</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#disease-background">8.3.1 Disease Background</a></li>
<li class="toctree-l3"><a class="reference internal" href="#python-implementation">8.3.2. Python Implementation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#prediction-of-an-unknown-case">8.3.3. Prediction of an Unknown Case</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#case-1">8.3.3.1. Case.1</a></li>
<li class="toctree-l4"><a class="reference internal" href="#case-2">8.3.3.2. Case.2</a></li>
<li class="toctree-l4"><a class="reference internal" href="#case-3">8.3.3.3. Case.3</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="contact.html">About the Author</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Jafar Arash Mehr</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li><strong>8. Machine Learning in Diagnosis</strong></li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/rst/LDA.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="machine-learning-in-diagnosis">
<h1><strong>8. Machine Learning in Diagnosis</strong><a class="headerlink" href="#machine-learning-in-diagnosis" title="Permalink to this heading"></a></h1>
<section id="linear-discriminant-analysis">
<h2>8.1. Linear Discriminant Analysis<a class="headerlink" href="#linear-discriminant-analysis" title="Permalink to this heading"></a></h2>
<p>Machine Learning (ML) is a branch of artificial intelligence that employs a wide range of techniques and tools which are helpful in diagnostic applications in a variety of medical areas like
diagnosis and detection of diseases. These methods are being used in a variety of applications in order to identify, classify and detect different diseases ranging from cancer and Alzheimer
to ophthalmology. Linear Discriminant Analysis is a supervised classification technique in machine learning for
dimensionality reduction applications. In this method we seek to reduce the dimensions by taking off the unimportant and redundant features by transforming the features from higher dimensional
space to a lower dimensional space where the data achieves maximum class separability</p>
</section>
<section id="mathematical-background">
<h2>8.2. Mathematical Background<a class="headerlink" href="#mathematical-background" title="Permalink to this heading"></a></h2>
<p>In the LDA, the derived features are linear combinations of the original features. For implementation we can start off by calculating two matrices including within-class <span class="math notranslate nohighlight">\(S_W`and
between-class :math:`S_B\)</span>. The <span class="math notranslate nohighlight">\(S_W\)</span> and <span class="math notranslate nohighlight">\(S_B\)</span> are two <span class="math notranslate nohighlight">\(n \times n\)</span> matrices indicating the number of features in the data where <span class="math notranslate nohighlight">\(n\)</span> is the number of the features.
The <span class="math notranslate nohighlight">\(S_W\)</span> corresponds to the separability between different classes (i.e. the distance between the mean of different classes). The optimal transformation in classical LDA is achieved by minimizing the <span class="math notranslate nohighlight">\(S_W\)</span> distance and maximizing the <span class="math notranslate nohighlight">\(S_B\)</span> distance simultaneously, leading to maximum discrimination. The <span class="math notranslate nohighlight">\(S_W\)</span> is represented as following:</p>
<div class="math notranslate nohighlight" id="eq-100">
<span id="equation-eq-100"></span><span class="eqno">(113)<a class="headerlink" href="#eq-100" title="Permalink to this equation"></a></span>\[ S_W=  \sum_{i_=1}^{class} S_i \quad Where \quad  S_i = \sum_{j_=1}^{n} (x_j-m_i)(x_j-m_i)^T\]</div>
<p>In the above equations, the class represent the classes (e.g. Normal, Low-Flattened and High-Flattened globes). <span class="math notranslate nohighlight">\(X\)</span> is
the number of the samples including the features in each class. The <span class="math notranslate nohighlight">\(m\)</span> is a vector including the mean of each feature in each class:</p>
<div class="math notranslate nohighlight" id="eq-101">
<span id="equation-eq-101"></span><span class="eqno">(114)<a class="headerlink" href="#eq-101" title="Permalink to this equation"></a></span>\[ m_i= \frac {1}{n_i} \sum_{k=1}{n} X_k\]</div>
<p>The <span class="math notranslate nohighlight">\(S_B\)</span> is computed as following:</p>
<div class="math notranslate nohighlight" id="eq-102">
<span id="equation-eq-102"></span><span class="eqno">(115)<a class="headerlink" href="#eq-102" title="Permalink to this equation"></a></span>\[ S_B= \sum_{I=1}^{c} N_i(m_i-\mu)(m_i-\mu)^T\]</div>
<p>Where <span class="math notranslate nohighlight">\(\mu\)</span> is a vector containing the mean of all the samples in all of the classes. In the LDA analysis we try to obtain the lower dimensional space in a way that it maximizes the between class variance and minimizes the within class variance. We can transform data using a transformation matrix <span class="math notranslate nohighlight">\(\xi\)</span> .With that being said, the transformed dataset (Y), could be written as:</p>
<div class="math notranslate nohighlight" id="eq-103">
<span id="equation-eq-103"></span><span class="eqno">(116)<a class="headerlink" href="#eq-103" title="Permalink to this equation"></a></span>\[ Y = \xi^T \times X\]</div>
<p>In order to obtain a good separation between classes we seek to maximize the <span class="math notranslate nohighlight">\(\frac{S_B}{S_W}\)</span>. By applying this transformation to <span class="math notranslate nohighlight">\(S_B\)</span> and <span class="math notranslate nohighlight">\(S_W\)</span> :</p>
<div class="math notranslate nohighlight" id="eq-104">
<span id="equation-eq-104"></span><span class="eqno">(117)<a class="headerlink" href="#eq-104" title="Permalink to this equation"></a></span>\[ S_W= \sum_{I=I}^{class} \sum_{j=1}^{class} [(\xi^T(x_j-m_i)(\xi^T(x_j-m_i))^T]_i=\xi^T S_W \xi\]</div>
<div class="math notranslate nohighlight" id="eq-105">
<span id="equation-eq-105"></span><span class="eqno">(118)<a class="headerlink" href="#eq-105" title="Permalink to this equation"></a></span>\[ S_B= \sum_{I=I}^{class} N_i [(\xi^T(m_i-m)(\xi^T(m_i-m))^T]=\xi^T S_B \xi\]</div>
<p>Then the equation  becomes  <span class="math notranslate nohighlight">\(\frac{\xi^T S_B \xi}{\xi^T S_W \xi}\)</span>. Now we can find the <span class="math notranslate nohighlight">\(\xi\)</span> that maximizes this equation. It turns out that <span class="math notranslate nohighlight">\(\xi\)</span> can be found by calculating the Eigenvectors of <span class="math notranslate nohighlight">\({S_W}^{-1} S_B\)</span>.
In other words, we can look at it as a constrained optimization problem with <span class="math notranslate nohighlight">\(\xi^T S_W \xi = P\)</span>.To this end, we can rewrite this in Lagrangian form:</p>
<div class="math notranslate nohighlight" id="eq-106">
<span id="equation-eq-106"></span><span class="eqno">(119)<a class="headerlink" href="#eq-106" title="Permalink to this equation"></a></span>\[ L=\xi^T S_B \xi - \lambda (\xi^T S_W \xi - P)\]</div>
<p>Then we can take the derivative of the above equation and set it equal to zero:</p>
<div class="math notranslate nohighlight" id="eq-107">
<span id="equation-eq-107"></span><span class="eqno">(120)<a class="headerlink" href="#eq-107" title="Permalink to this equation"></a></span>\[ \frac{\partial L}{\partial \xi} = 2(S_B-\lambda S_W) \xi = 0\]</div>
<p>Which gives:</p>
<div class="math notranslate nohighlight" id="eq-108">
<span id="equation-eq-108"></span><span class="eqno">(121)<a class="headerlink" href="#eq-108" title="Permalink to this equation"></a></span>\[ S_B \xi = \lambda S_W \xi\]</div>
<p>The above generalized eigenvalue problem can be written as following:</p>
<div class="math notranslate nohighlight" id="eq-109">
<span id="equation-eq-109"></span><span class="eqno">(122)<a class="headerlink" href="#eq-109" title="Permalink to this equation"></a></span>\[ {S_W}^{-1} S_B \xi = \lambda \xi\]</div>
<div class="math notranslate nohighlight" id="eq-110">
<span id="equation-eq-110"></span><span class="eqno">(123)<a class="headerlink" href="#eq-110" title="Permalink to this equation"></a></span>\[ {S_W}^{-1} S_B \xi - \lambda \xi = 0 \Rightarrow {S_W}^{-1} S_B \xi - \lambda I \xi = 0\]</div>
<p>The above equation could be written as following:</p>
<div class="math notranslate nohighlight" id="eq-111">
<span id="equation-eq-111"></span><span class="eqno">(124)<a class="headerlink" href="#eq-111" title="Permalink to this equation"></a></span>\[ ({S_W}^{-1} S_B - \lambda I) \xi = 0\]</div>
<p>Solving this equation gives the eigenvalues (<span class="math notranslate nohighlight">\(\lambda_i\)</span>) and corresponding eigenvectors of the <span class="math notranslate nohighlight">\(S_W^{-1} S_B\)</span>
matrix.</p>
</section>
<section id="a-real-medical-application">
<h2>8.3. A Real Medical Application<a class="headerlink" href="#a-real-medical-application" title="Permalink to this heading"></a></h2>
<section id="disease-background">
<h3>8.3.1 Disease Background<a class="headerlink" href="#disease-background" title="Permalink to this heading"></a></h3>
<p>In this section, we use the LDA in a real world application in order to detect an eye-related disease. This eye disorder is called Idiopathic intracranial hypertension (IIH). The IIH occurs most frequently among obese women and astronauts coming back from long-duration space mission. The most common symptoms of this disease include daily and persistent headache , transient visual obscuration and nausea.
Flattening of the posterior eye globe in the magnetic resonance (MR) images is known as one of the most important signs in the patients diagnosed with IIH. In this regards, mechanical factors have been proposed to play role in such phenomenon. These mechanical factors include the material properties of the tissue within the optic nerve head and also the pressure loads like ICP and intraocular pressure (IOP). This eye disease has also been studied using numerical model based on finite element method:</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Here is the reference:</p>
<blockquote>
<div><p><a class="reference external" href="https://www.mdpi.com/2075-1729/10/12/316">Numerical Investigation on the Role of Mechanical Factors Contributing to Globe Flattening in States of Elevated Intracranial Pressure</a></p>
</div></blockquote>
</div>
<p>In general, the degree of flattening of the posterior of the eye globe could represent the severity of this disease. To be more specific, the higher the degree of flattening, the more severe the disease.
The eye globe could be modeled as an axisymetric finite element model where the flattening of the posterior of the globe is represented by <span class="math notranslate nohighlight">\(\alpha\)</span> and <span class="math notranslate nohighlight">\(\beta\)</span>. Now a new parameter is introduced which is called Cut-Off angle (<span class="math notranslate nohighlight">\(\beta\)</span>) as an angle (<span class="math notranslate nohighlight">\(\theta\)</span>) in which the slopes (<span class="math notranslate nohighlight">\(\alpha\)</span>) up to the <span class="math notranslate nohighlight">\(\beta\)</span> are fairly small (−0.5° ≤ <span class="math notranslate nohighlight">\(\alpha\)</span> ≤ 0.5°). The simplified eye model consisted of different tissues including Sclera (SC), Peripapillary Sclera (PSC), Dura Mater (DM), Retina (RET), Vessel (VES), Lamina Cribrosa (LC), Pia Mater (PM) and Optic Nerve (ON). These parameters are all shown in next figure:</p>
<figure class="align-center" id="id1">
<img alt="../_images/18.png" src="../_images/18.png" />
<figcaption>
<p><span class="caption-number">Fig. 17 </span><span class="caption-text">Illustration of the parameters <span class="math notranslate nohighlight">\(\alpha\)</span> , <span class="math notranslate nohighlight">\(\beta\)</span> and <span class="math notranslate nohighlight">\(\theta\)</span>. The tissues within the eye globe are shown in the left.</span><a class="headerlink" href="#id1" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<p>In general, the lower value of <span class="math notranslate nohighlight">\(\beta\)</span> indicates larger flattening area at the posterior of the eye globe that is equal to higher severity of this eye disease.
For a normal eye where there is no flattening at the posterior of the globe, the <span class="math notranslate nohighlight">\(\beta=90°\)</span>. For an eye globe where the area of flattening is relatively small, the <span class="math notranslate nohighlight">\(\beta=80°\)</span>. Finally the eye globe with largest degree of globe flattening is the eye with the <span class="math notranslate nohighlight">\(\beta=70°\)</span>.</p>
</section>
<section id="python-implementation">
<h3>8.3.2. Python Implementation<a class="headerlink" href="#python-implementation" title="Permalink to this heading"></a></h3>
<p>According to these 3 classes, we are given 1211 eye globes including 360 normal eye globe, 550 eye globes with low globe flattening and 301 eye globe with high globe flattening. The different classes are shown in this table:</p>
<table class="docutils align-default" id="tab-3">
<caption><span class="caption-number">Table 4 </span><span class="caption-text">The criteria defining different levels of globe flattening</span><a class="headerlink" href="#tab-3" title="Permalink to this table"></a></caption>
<colgroup>
<col style="width: 37%" />
<col style="width: 26%" />
<col style="width: 37%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>Class Description</p></td>
<td><p><span class="math notranslate nohighlight">\(\beta\)</span> (Degrees)</p></td>
<td><p>Number of eye globe</p></td>
</tr>
<tr class="row-even"><td><p>Normal Globe</p></td>
<td><p>90</p></td>
<td><p>360</p></td>
</tr>
<tr class="row-odd"><td><p>Low - Flattened Globe</p></td>
<td><p>80</p></td>
<td><p>550</p></td>
</tr>
<tr class="row-even"><td><p>High - Flattened Globe</p></td>
<td><p>70</p></td>
<td><p>301</p></td>
</tr>
</tbody>
</table>
<p>From the mechanical point of view, we have 9 different mechanical features playing role in the deformation of the eye globe two of which are internal pressures including the IOP and ICP. The remaining 7 features are the material properties of the constitutive tissues as shown previously.
If want to visualize our classes, this is not feasible to do it on a 9-dimensional space. Instead, we take advantage of LDA in order to project the results on a 2-dimensional space where the classes are separated from each other.
Regarding the given eye globes, we have information of the pressures  (IOP and ICP) as well as estimation of the material properties of the all tissues inside each globe.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>All values should be used after normalization meaning that for each feature, all data should be divided by the maximum value in the corresponding feature. With that being said, all data are values between 0 and 1. We should write all data in a text file. Each line in the text file correspond to 1 eye globe that has 9 numbers which are the normalized values of the features for that particular eye separated by “,” and the last item in the line is the name of the class that the eye globe belongs to. It should be either “A” or “B” or “C” corresponding to the “High Flattened”, “Low Flattened” and “Normal” eye globes.</p>
</div>
<p>Here is an example of one line in the text file for an eye globe belonging to the high-flattened class:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="mf">0.25</span><span class="p">,</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.2</span><span class="p">,</span><span class="mf">0.04</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mf">0.1111111111</span><span class="p">,</span><span class="mf">0.1111111111</span><span class="p">,</span><span class="mf">0.6665</span><span class="p">,</span><span class="mf">0.33325</span><span class="p">,</span><span class="n">A</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The name of the text file is : <strong>LARGE-NORMALIZED.txt</strong> including 1211 lines and is available in the github repository in the folder <strong>EYE-MODELS</strong></p>
</div>
<p>Here is the Python implementation of the LDA analysis on the given data. We use <strong>Panda</strong> and <strong>Scikitlearn</strong> for reading and preprocessing of the data including the features and classes. In the meantime, we use <strong>Numpy</strong> for mathematical implementation of the LDA analysis:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="c1"># Here we should define all 9 features including 9 material properties and 2 pressures</span>
<span class="n">feature_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span><span class="n">label</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">label</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
                <span class="nb">range</span><span class="p">(</span><span class="mi">9</span><span class="p">),(</span><span class="s1">&#39;SC&#39;</span><span class="p">,</span><span class="s1">&#39;PSC&#39;</span><span class="p">,</span><span class="s1">&#39;PIA&#39;</span><span class="p">,</span><span class="s1">&#39;DURA&#39;</span><span class="p">,</span><span class="s1">&#39;LC&#39;</span><span class="p">,</span><span class="s1">&#39;RET&#39;</span><span class="p">,</span><span class="s1">&#39;ON&#39;</span><span class="p">,</span><span class="s1">&#39;IOP&#39;</span><span class="p">,</span><span class="s1">&#39;ICP&#39;</span><span class="p">))}</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;LARGE-NORMALIZED.txt&#39;</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">l</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">l</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">feature_dict</span><span class="o">.</span><span class="n">items</span><span class="p">())]</span> <span class="o">+</span> <span class="p">[</span><span class="s1">&#39;class label&#39;</span><span class="p">]</span>
<span class="n">df</span><span class="o">.</span><span class="n">tail</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">ix</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="mi">9</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">ix</span><span class="p">[:,</span><span class="mi">9</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">label_dict</span> <span class="o">=</span> <span class="p">{</span><span class="mi">1</span><span class="p">:</span> <span class="s1">&#39;High-Flattened&#39;</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span> <span class="s1">&#39;Low-Flattened&#39;</span><span class="p">,</span> <span class="mi">3</span><span class="p">:</span><span class="s1">&#39;Normal&#39;</span><span class="p">}</span>

<span class="n">enc</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">label_encoder</span> <span class="o">=</span> <span class="n">enc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">label_encoder</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>

<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

<span class="n">mean_vectors</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">cl</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">):</span>
    <span class="n">mean_vectors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="n">cl</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>

<span class="c1"># S_W is 9x9 matrix</span>
<span class="n">S_W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">9</span><span class="p">,</span><span class="mi">9</span><span class="p">))</span>
<span class="k">for</span> <span class="n">cl</span><span class="p">,</span><span class="n">mv</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span> <span class="n">mean_vectors</span><span class="p">):</span>
    <span class="n">class_sc_mat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">9</span><span class="p">,</span><span class="mi">9</span><span class="p">))</span>                  <span class="c1"># scatter matrix for every class</span>
    <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">X</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="n">cl</span><span class="p">]:</span>
        <span class="n">row</span><span class="p">,</span> <span class="n">mv</span> <span class="o">=</span> <span class="n">row</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">mv</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># make column vectors</span>
        <span class="n">class_sc_mat</span> <span class="o">+=</span> <span class="p">(</span><span class="n">row</span><span class="o">-</span><span class="n">mv</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">((</span><span class="n">row</span><span class="o">-</span><span class="n">mv</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">S_W</span> <span class="o">+=</span> <span class="n">class_sc_mat</span>                             <span class="c1"># sum class scatter matrices</span>

<span class="n">overall_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># S_B is 9x9 matrix</span>
<span class="n">S_B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">9</span><span class="p">,</span><span class="mi">9</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">mean_vec</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">mean_vectors</span><span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,:]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">mean_vec</span> <span class="o">=</span> <span class="n">mean_vec</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># make column vector</span>
    <span class="n">overall_mean</span> <span class="o">=</span> <span class="n">overall_mean</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># make column vector</span>
    <span class="n">S_B</span> <span class="o">+=</span> <span class="n">n</span> <span class="o">*</span> <span class="p">(</span><span class="n">mean_vec</span> <span class="o">-</span> <span class="n">overall_mean</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">((</span><span class="n">mean_vec</span> <span class="o">-</span> <span class="n">overall_mean</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

<span class="n">eig_vals</span><span class="p">,</span> <span class="n">eig_vecs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eig</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">S_W</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">S_B</span><span class="p">))</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">eig_vals</span><span class="p">)):</span>
    <span class="n">eigvec_sc</span> <span class="o">=</span> <span class="n">eig_vecs</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>

<span class="n">eig_pairs</span> <span class="o">=</span> <span class="p">[(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">eig_vals</span><span class="p">[</span><span class="n">i</span><span class="p">]),</span> <span class="n">eig_vecs</span><span class="p">[:,</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">eig_vals</span><span class="p">))]</span>

<span class="c1"># Sort the (eigenvalue, eigenvector) tuples from high to low</span>
<span class="n">eig_pairs</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">eig_pairs</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">k</span><span class="p">:</span> <span class="n">k</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Variance explained:</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">eigv_sum</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">eig_vals</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">j</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">eig_pairs</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;eigenvalue </span><span class="si">{0:}</span><span class="s1">: </span><span class="si">{1:.2%}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="n">j</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="n">eigv_sum</span><span class="p">)</span><span class="o">.</span><span class="n">real</span><span class="p">))</span>

<span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">eig_pairs</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">eig_pairs</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">1</span><span class="p">)))</span>
<span class="n">X_lda</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W</span><span class="p">)</span>

<span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="s1">&#39;seaborn-whitegrid&#39;</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">label</span><span class="p">,</span> <span class="n">marker</span><span class="p">,</span> <span class="n">color</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;^&#39;</span><span class="p">,</span> <span class="s1">&#39;s&#39;</span><span class="p">,</span> <span class="s1">&#39;o&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span><span class="s1">&#39;g&#39;</span><span class="p">)):</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_lda</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">real</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="n">label</span><span class="p">],</span>
                    <span class="n">y</span><span class="o">=</span><span class="n">X_lda</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">real</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="n">label</span><span class="p">],</span>
                    <span class="n">marker</span><span class="o">=</span><span class="n">marker</span><span class="p">,</span>
                    <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span>
                    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                    <span class="n">label</span><span class="o">=</span><span class="n">label_dict</span><span class="p">[</span><span class="n">label</span><span class="p">])</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;LDA 1&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">25</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;LDA 2&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">25</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mf">1.0</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">&#39;major&#39;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;lower right&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;Results.png&#39;</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s1">&#39;png&#39;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">1200</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p>Here is the output of the code:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">Variance</span> <span class="n">explained</span><span class="p">:</span>

                <span class="n">eigenvalue</span> <span class="mi">1</span><span class="p">:</span> <span class="mf">80.74</span><span class="o">%</span>
                <span class="n">eigenvalue</span> <span class="mi">2</span><span class="p">:</span> <span class="mf">18.26</span><span class="o">%</span>
                <span class="n">eigenvalue</span> <span class="mi">3</span><span class="p">:</span> <span class="mf">0.00</span><span class="o">%</span>
                <span class="n">eigenvalue</span> <span class="mi">4</span><span class="p">:</span> <span class="mf">0.00</span><span class="o">%</span>
                <span class="n">eigenvalue</span> <span class="mi">5</span><span class="p">:</span> <span class="mf">0.00</span><span class="o">%</span>
                <span class="n">eigenvalue</span> <span class="mi">6</span><span class="p">:</span> <span class="mf">0.00</span><span class="o">%</span>
                <span class="n">eigenvalue</span> <span class="mi">7</span><span class="p">:</span> <span class="mf">0.00</span><span class="o">%</span>
                <span class="n">eigenvalue</span> <span class="mi">8</span><span class="p">:</span> <span class="mf">0.00</span><span class="o">%</span>
                <span class="n">eigenvalue</span> <span class="mi">9</span><span class="p">:</span> <span class="mf">0.00</span><span class="o">%</span>
</pre></div>
</div>
<p>The above shows the sorted Variance explained where it is has become zero in 7 directions and only 2 directions have remained (LDA1 &amp; LDA2) where the variance explained are largest.</p>
<p>In the below figure, we can see how the classes have been projected on the 2D space and separated from each other:</p>
<figure class="align-center" id="id2">
<img alt="../_images/15.png" src="../_images/15.png" />
<figcaption>
<p><span class="caption-number">Fig. 18 </span><span class="caption-text">Separation of the classes including the Normal eyes, Lowe-Flattened eyes and High-Flattened eyes after implementation of the LDA analysis on the data.</span><a class="headerlink" href="#id2" title="Permalink to this image"></a></p>
</figcaption>
</figure>
</section>
<section id="prediction-of-an-unknown-case">
<h3>8.3.3. Prediction of an Unknown Case<a class="headerlink" href="#prediction-of-an-unknown-case" title="Permalink to this heading"></a></h3>
<p>Now, lets say how we can use the LDA as a supervised machine learning technique to make prediction on an eye globe where we do not know which class it belongs to. We have the information about the values of the features including the material properties and also the pressures for that eye globe.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>We do not know how deformation in an eye globe with these features could be. In addition, we do not have any MR image of this particular eye globe to figure out if this is a normal, low flattened  or high flattened eye globe.</p>
</div>
<p>We should normalize the given data from this unknown case and then add a new line to the text file with a new class name like <strong>D</strong> corresponding to the unknown class. With that being said, after adding the new line, we need to implement some minor changes in the previous code to visualize the location of the new data (e.g., Unknown Case):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="c1"># Here we should define all 9 features including 9 material properties and 2 pressures</span>
<span class="n">feature_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span><span class="n">label</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">label</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
                <span class="nb">range</span><span class="p">(</span><span class="mi">9</span><span class="p">),(</span><span class="s1">&#39;SC&#39;</span><span class="p">,</span><span class="s1">&#39;PSC&#39;</span><span class="p">,</span><span class="s1">&#39;PIA&#39;</span><span class="p">,</span><span class="s1">&#39;DURA&#39;</span><span class="p">,</span><span class="s1">&#39;LC&#39;</span><span class="p">,</span><span class="s1">&#39;RET&#39;</span><span class="p">,</span><span class="s1">&#39;ON&#39;</span><span class="p">,</span><span class="s1">&#39;IOP&#39;</span><span class="p">,</span><span class="s1">&#39;ICP&#39;</span><span class="p">))}</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;LARGE-NORMALIZED.txt&#39;</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">l</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">l</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">feature_dict</span><span class="o">.</span><span class="n">items</span><span class="p">())]</span> <span class="o">+</span> <span class="p">[</span><span class="s1">&#39;class label&#39;</span><span class="p">]</span>
<span class="n">df</span><span class="o">.</span><span class="n">tail</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">ix</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="mi">9</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">ix</span><span class="p">[:,</span><span class="mi">9</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">label_dict</span> <span class="o">=</span> <span class="p">{</span><span class="mi">1</span><span class="p">:</span> <span class="s1">&#39;High-Flattened&#39;</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span> <span class="s1">&#39;Low-Flattened&#39;</span><span class="p">,</span> <span class="mi">3</span><span class="p">:</span><span class="s1">&#39;Normal&#39;</span><span class="p">,</span><span class="mi">4</span><span class="p">:</span> <span class="s1">&#39;Unknown Class&#39;</span><span class="p">}</span>

<span class="n">enc</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">label_encoder</span> <span class="o">=</span> <span class="n">enc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">label_encoder</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>

<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

<span class="n">mean_vectors</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">cl</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">):</span>
    <span class="n">mean_vectors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="n">cl</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>

<span class="c1"># S_W is 9x9 matrix</span>
<span class="n">S_W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">9</span><span class="p">,</span><span class="mi">9</span><span class="p">))</span>
<span class="k">for</span> <span class="n">cl</span><span class="p">,</span><span class="n">mv</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> <span class="n">mean_vectors</span><span class="p">):</span>
    <span class="n">class_sc_mat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">9</span><span class="p">,</span><span class="mi">9</span><span class="p">))</span>                  <span class="c1"># scatter matrix for every class</span>
    <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">X</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="n">cl</span><span class="p">]:</span>
        <span class="n">row</span><span class="p">,</span> <span class="n">mv</span> <span class="o">=</span> <span class="n">row</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">mv</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># make column vectors</span>
        <span class="n">class_sc_mat</span> <span class="o">+=</span> <span class="p">(</span><span class="n">row</span><span class="o">-</span><span class="n">mv</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">((</span><span class="n">row</span><span class="o">-</span><span class="n">mv</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">S_W</span> <span class="o">+=</span> <span class="n">class_sc_mat</span>                             <span class="c1"># sum class scatter matrices</span>

<span class="n">overall_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># S_B is 9x9 matrix</span>
<span class="n">S_B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">9</span><span class="p">,</span><span class="mi">9</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">mean_vec</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">mean_vectors</span><span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,:]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">mean_vec</span> <span class="o">=</span> <span class="n">mean_vec</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># make column vector</span>
    <span class="n">overall_mean</span> <span class="o">=</span> <span class="n">overall_mean</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># make column vector</span>
    <span class="n">S_B</span> <span class="o">+=</span> <span class="n">n</span> <span class="o">*</span> <span class="p">(</span><span class="n">mean_vec</span> <span class="o">-</span> <span class="n">overall_mean</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">((</span><span class="n">mean_vec</span> <span class="o">-</span> <span class="n">overall_mean</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

<span class="n">eig_vals</span><span class="p">,</span> <span class="n">eig_vecs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eig</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">S_W</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">S_B</span><span class="p">))</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">eig_vals</span><span class="p">)):</span>
    <span class="n">eigvec_sc</span> <span class="o">=</span> <span class="n">eig_vecs</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>

<span class="n">eig_pairs</span> <span class="o">=</span> <span class="p">[(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">eig_vals</span><span class="p">[</span><span class="n">i</span><span class="p">]),</span> <span class="n">eig_vecs</span><span class="p">[:,</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">eig_vals</span><span class="p">))]</span>

<span class="c1"># Sort the (eigenvalue, eigenvector) tuples from high to low</span>
<span class="n">eig_pairs</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">eig_pairs</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">k</span><span class="p">:</span> <span class="n">k</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Variance explained:</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">eigv_sum</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">eig_vals</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">j</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">eig_pairs</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;eigenvalue </span><span class="si">{0:}</span><span class="s1">: </span><span class="si">{1:.2%}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="n">j</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="n">eigv_sum</span><span class="p">)</span><span class="o">.</span><span class="n">real</span><span class="p">))</span>

<span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">eig_pairs</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">eig_pairs</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">1</span><span class="p">)))</span>
<span class="n">X_lda</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W</span><span class="p">)</span>

<span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="s1">&#39;seaborn-whitegrid&#39;</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">label</span><span class="p">,</span> <span class="n">marker</span><span class="p">,</span> <span class="n">color</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;^&#39;</span><span class="p">,</span> <span class="s1">&#39;s&#39;</span><span class="p">,</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span><span class="s1">&#39;*&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span><span class="s1">&#39;g&#39;</span><span class="p">,</span><span class="s1">&#39;k&#39;</span><span class="p">)):</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_lda</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">real</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="n">label</span><span class="p">],</span>
                    <span class="n">y</span><span class="o">=</span><span class="n">X_lda</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">real</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="n">label</span><span class="p">],</span>
                    <span class="n">marker</span><span class="o">=</span><span class="n">marker</span><span class="p">,</span>
                    <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span>
                    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                    <span class="n">label</span><span class="o">=</span><span class="n">label_dict</span><span class="p">[</span><span class="n">label</span><span class="p">])</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;LDA 1&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">25</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;LDA 2&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">25</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mf">1.0</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">&#39;major&#39;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;lower right&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;Results.png&#39;</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s1">&#39;png&#39;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">1200</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p>The new unknown data will be shown on the space as a black ★. This way we can see inside which class the new data will fall in.</p>
<section id="case-1">
<h4>8.3.3.1. Case.1<a class="headerlink" href="#case-1" title="Permalink to this heading"></a></h4>
<p>Here is the information regarding the first unknow case that should be added as a line to the data (<strong>LARGE-NORMALIZED.txt</strong>). Here is the line:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="mf">0.05</span><span class="p">,</span><span class="mf">0.25</span><span class="p">,</span><span class="mf">0.2</span><span class="p">,</span><span class="mf">0.2</span><span class="p">,</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mf">0.3333333333</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mf">0.33325</span><span class="p">,</span><span class="n">D</span>
</pre></div>
</div>
<p>We can visualize where the data is located in this figure:</p>
<figure class="align-center" id="id3">
<img alt="../_images/16.png" src="../_images/16.png" />
<figcaption>
<p><span class="caption-number">Fig. 19 </span><span class="caption-text">Illustration of the new data. The arrow points at the location where the data is located</span><a class="headerlink" href="#id3" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<p>It could be clearly seen that this case belongs to the high-flattened class.</p>
</section>
<section id="case-2">
<h4>8.3.3.2. Case.2<a class="headerlink" href="#case-2" title="Permalink to this heading"></a></h4>
<p>Here is the information regarding the second unknown case that should be added as a line to the data (<strong>LARGE-NORMALIZED.txt</strong>). Here is the line:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.04</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mf">0.3333333333</span><span class="p">,</span><span class="mf">0.1111111111</span><span class="p">,</span><span class="mf">0.33325</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">D</span>
</pre></div>
</div>
<p>We can visualize where the second unknown data is located in this figure:</p>
<figure class="align-center" id="id4">
<img alt="../_images/17.png" src="../_images/17.png" />
<figcaption>
<p><span class="caption-number">Fig. 20 </span><span class="caption-text">Illustration of the second unknown data. The arrow points at the location where the data is located</span><a class="headerlink" href="#id4" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<p>It is obvious that this case belongs to the low-flattened class.</p>
</section>
<section id="case-3">
<h4>8.3.3.3. Case.3<a class="headerlink" href="#case-3" title="Permalink to this heading"></a></h4>
<p>Here is the information regarding the third unknown case that should be added as a line to the data (<strong>LARGE-NORMALIZED.txt</strong>). Here is the line:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="mi">1</span><span class="p">,</span><span class="mf">0.11</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mf">0.03</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mf">0.22</span><span class="p">,</span><span class="mf">0.3333333333</span><span class="p">,</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.11</span><span class="p">,</span><span class="n">D</span>
</pre></div>
</div>
<p>We can visualize where the third unknown data is located in this figure:</p>
<figure class="align-center" id="id5">
<img alt="../_images/18.png" src="../_images/18.png" />
<figcaption>
<p><span class="caption-number">Fig. 21 </span><span class="caption-text">Illustration of the third unknown data. The arrow points at the location where the data is located</span><a class="headerlink" href="#id5" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<p>This case, clearly falls within the normal class.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The accuracy of the prediction of the LDA analysis to determine the class of disease could be verified after doing the FEM simulation based on the criteria defined in <a class="reference internal" href="#tab-3"><span class="std std-ref">Table.3</span></a></p>
</div>
</section>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="ML.html" class="btn btn-neutral float-left" title="7. Fundamentals of Machine Learning" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="contact.html" class="btn btn-neutral float-right" title="About the Author" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Jafar Arash Mehr.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>