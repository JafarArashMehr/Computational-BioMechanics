<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>6. Linear Regression &mdash; Jafar Arash Mehr 2022 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="7. Fundamentals of Machine Learning" href="ML.html" />
    <link rel="prev" title="5. Statistical Analysis" href="Statistical%20Analysis.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html">
            <img src="../_static/profile.jpg" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="Intro.html"><strong>What is this document about?</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="resource.html">Useful Resources</a></li>
<li class="toctree-l1"><a class="reference internal" href="package.html">Required Packages</a></li>
<li class="toctree-l1"><a class="reference internal" href="hyperelasticity.html"><strong>1. Hyperelasticity</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="multi-physics.html"><strong>2. Multi-Physics Problem</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="drug-delivery.html"><strong>3. Drug Delivery</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="optimization.html"><strong>4. Inverse Finite Element (Optimization)</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="Statistical%20Analysis.html"><strong>5. Statistical Analysis</strong></a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#"><strong>6. Linear Regression</strong></a><ul>
<li class="toctree-l2"><a class="reference internal" href="#simple-linear-regression">6.1. Simple linear regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="#multiple-linear-regression">6.2. Multiple linear regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="#hypothesis-testing">6.3. Hypothesis testing</a></li>
<li class="toctree-l2"><a class="reference internal" href="#logistic-regression">6.4. Logistic regression</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="ML.html"><strong>7. Fundamentals of Machine Learning</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="LDA.html"><strong>8. Machine Learning in Diagnosis</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="contact.html">About the Author</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Jafar Arash Mehr</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li><strong>6. Linear Regression</strong></li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/rst/Linear Regression.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="linear-regression">
<h1><strong>6. Linear Regression</strong><a class="headerlink" href="#linear-regression" title="Permalink to this heading"></a></h1>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>All of required CSV files are available in the folder: <strong>Linear Regression.txt</strong></p>
</div>
<section id="simple-linear-regression">
<h2>6.1. Simple linear regression<a class="headerlink" href="#simple-linear-regression" title="Permalink to this heading"></a></h2>
<p>Using linear regression we define a linear relationship between a dependent variable (Y) and an independent variable (X):</p>
<div class="math notranslate nohighlight" id="eq-113">
<span id="equation-eq-113"></span><span class="eqno">(103)<a class="headerlink" href="#eq-113" title="Permalink to this equation"></a></span>\[ Y= aX+b\]</div>
<p>In above equation, <span class="math notranslate nohighlight">\(a\)</span> and <span class="math notranslate nohighlight">\(b\)</span> are the slope and intercept parameters.</p>
<p>The purpose of using linear regression is to explore the relationship between two continuous variables. To this end, we need to perform a complete simple linear regression analysis. Here are the main steps:</p>
<ol class="arabic simple">
<li><p>Creating and fitting a model,</p></li>
<li><p>Checking model assumptions,</p></li>
<li><p>Analyzing model performance,</p></li>
<li><p>Interpreting model coefficients,</p></li>
</ol>
<p>We have a dataset about influencer marketing. We want to  explore the relationship between marketing promotional budgets and sales. The dataset provided includes information about marketing campaigns across TV, radio, and social media, as well as how much revenue in sales was generated from these campaigns. Based on this information, we want to make decisions about where to focus future marketing efforts, so it is critical to have a clear understanding of the relationship between the different types of marketing and the revenue they generate.</p>
<p>First we should import required Python libraries including: pandas, pyplot from matplotlib, and seaborn.In addition Import the statsmodels.api Python module using its common abbreviation, sm, along with the ols() function from statsmodels.formula.api:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="c1"># Import the statsmodel module.</span>
<span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="nn">sm</span>

<span class="c1"># Import the ols function from statsmodels.</span>
<span class="kn">from</span> <span class="nn">statsmodels.formula.api</span> <span class="kn">import</span> <span class="n">ols</span>
</pre></div>
</div>
<p>In the next step we need to load the dataset (modified_marketing_and_sales_data.csv):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;modified_marketing_and_sales_data.csv&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>The features in the data are:</p>
<p><span class="math notranslate nohighlight">\(\bullet\)</span> TV promotion budget (in millions of dollars)</p>
<p><span class="math notranslate nohighlight">\(\bullet\)</span> Social media promotion budget (in millions of dollars)</p>
<p><span class="math notranslate nohighlight">\(\bullet\)</span> Radio promotion budget (in millions of dollars)</p>
<p><span class="math notranslate nohighlight">\(\bullet\)</span> Sales (in millions of dollars)</p>
<p>Each row corresponds to an independent marketing promotion where the business invests in TV, Social_Media, and Radio promotions to increase Sales. We want to determine which feature most strongly predicts Sales so they have a better understanding of what promotions they should invest in in the future. To accomplish this, you’ll construct a simple linear regression model that predicts sales using a single independent variable.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Several investigations are required before making the regression models including:</p>
<p><span class="math notranslate nohighlight">\(\bullet\)</span> Understanding which variables are present in the data</p>
<p><span class="math notranslate nohighlight">\(\bullet\)</span> Reviewing the distribution of features, such as minimum, mean, and maximum values</p>
<p><span class="math notranslate nohighlight">\(\bullet\)</span> Plotting the relationship between the independent and dependent variables to visualize which feature is the best choice for X</p>
<p><span class="math notranslate nohighlight">\(\bullet\)</span> Identifying issues with the data, such as incorrect values (e.g., typos) or missing values</p>
</div>
<p>There are three continuous independent variables: TV, Radio, and Social_Media. To understand how heavily the business invests in each promotion type, use describe() to generate descriptive statistics for these three variables:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">data</span><span class="p">[[</span><span class="s1">&#39;TV&#39;</span><span class="p">,</span><span class="s1">&#39;Radio&#39;</span><span class="p">,</span><span class="s1">&#39;Social_Media&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
<p>Before fitting the model, ensure the Sales for each promotion (i.e., row) is present. If the Sales in a row is missing, that row isn’t of much value to the simple linear regression model.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Calculate the average missing rate in the sales column.</span>
<span class="n">missing_sales</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">Sales</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="c1"># Convert the missing_sales from a decimal to a percentage and round to 2 decimal places.</span>
<span class="n">missing_sales</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">missing_sales</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="c1"># Display the results (missing_sales must be converted to a string to be concatenated in the print statement).</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Percentage of promotions missing Sales: &#39;</span> <span class="o">+</span>  <span class="nb">str</span><span class="p">(</span><span class="n">missing_sales</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;%&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>Here is the output:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">Percentage</span> <span class="n">of</span> <span class="n">promotions</span> <span class="n">missing</span> <span class="n">Sales</span><span class="p">:</span> <span class="mf">0.13</span><span class="o">%</span>
</pre></div>
</div>
<p>Next step we should remove the missing data meaning that the rows that do not contain any Sale value:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Subset the data to include rows where Sales is present.</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">subset</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Sales&#39;</span><span class="p">],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<p>Then we can visualize the distribution of the Sale value in a histogram:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;Sales&#39;</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;c&#39;</span><span class="p">)</span>

<span class="c1"># Add a title</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Distribution of Sales&#39;</span><span class="p">);</span>
</pre></div>
</div>
<p>Here is the graph:</p>
<figure class="align-center">
<img alt="../_images/29.png" src="../_images/29.png" />
</figure>
<p>Now we can build the model. Create a pairplot to visualize the relationships between pairs of variables in the data. You will use this to visually determine which variable has the strongest linear relationship with Sales. This will help you select the X variable for the simple linear regression.</p>
<p>This could be done using this line of code:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">data</span><span class="p">);</span>
</pre></div>
</div>
<p>Here is the graph:</p>
<figure class="align-center">
<img alt="../_images/30.png" src="../_images/30.png" />
</figure>
<p>TV clearly has the strongest linear relationship with Sales. You could draw a straight line through the scatterplot of TV and Sales that confidently estimates Sales using TV.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Radio and Sales appear to have a linear relationship, but there is larger variance than between TV and Sales.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">data</span><span class="p">);</span>
</pre></div>
</div>
<p>Now we can use the <strong>Ordinary Least Squares</strong> function to fit the model and then see the summary of the results:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define the OLS formula.</span>
<span class="n">ols_formula</span> <span class="o">=</span> <span class="s1">&#39;Sales ~ TV&#39;</span>

<span class="c1"># Create an OLS model.</span>
<span class="n">OLS</span> <span class="o">=</span> <span class="n">ols</span><span class="p">(</span><span class="n">formula</span> <span class="o">=</span> <span class="n">ols_formula</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">)</span>

<span class="c1"># Fit the model.</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">OLS</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="c1"># Save the results summary.</span>
<span class="n">model_results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>

<span class="c1"># Display the model results.</span>
<span class="n">model_results</span>
</pre></div>
</div>
<p>Please note that when using simple linear regression, we should check four linear regression assumptions including:</p>
<ol class="arabic simple">
<li><p>Linearity</p></li>
<li><p>Independent Observations</p></li>
<li><p>Normality</p></li>
<li><p>Homoscedasticity (Constant variance)</p></li>
</ol>
<p><strong>1. Linearity</strong></p>
<p>To check the linearity, we need create a scatter plot comparing the X variable (independent variable:TV) with the dependent variable (Sales).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;TV&#39;</span><span class="p">],</span> <span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;Sales&#39;</span><span class="p">]);</span>
</pre></div>
</div>
<p>Here is the output:</p>
<figure class="align-center">
<img alt="../_images/31.png" src="../_images/31.png" />
</figure>
<p>There is a clear linear relationship between <cite>TV</cite> and <cite>Sales</cite>, meeting the linearity assumption.</p>
<p><strong>2. Independence</strong></p>
<p>The independent observation assumption states that each observation in the dataset is independent. In our data, each observation (Each row) is independent from one another, the independence assumption is not violated.</p>
<p><strong>3. Normality</strong></p>
<p>The normality assumption states that the errors are normally distributed. There are two ways to check the normality:</p>
<p><span class="math notranslate nohighlight">\(\bullet\)</span> Histogram of the residuals. (Differences between the actual and predicted values)</p>
<p><span class="math notranslate nohighlight">\(\bullet\)</span> Q-Q plot of the residuals</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">residuals</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">resid</span>

<span class="c1"># Create a 1x2 plot figure.</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>

<span class="c1"># Create a histogram with the residuals .</span>
<span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">residuals</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>

<span class="c1"># Set the x label of the residual plot.</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Residual Value&quot;</span><span class="p">)</span>

<span class="c1"># Set the title of the residual plot.</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Histogram of Residuals&quot;</span><span class="p">)</span>

<span class="c1"># Create a Q-Q plot of the residuals.</span>
<span class="n">sm</span><span class="o">.</span><span class="n">qqplot</span><span class="p">(</span><span class="n">residuals</span><span class="p">,</span> <span class="n">line</span><span class="o">=</span><span class="s1">&#39;s&#39;</span><span class="p">,</span><span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

<span class="c1"># Set the title of the Q-Q plot.</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Normal Q-Q plot&quot;</span><span class="p">)</span>

<span class="c1"># Use matplotlib&#39;s tight_layout() function to add space between plots for a cleaner appearance.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>

<span class="c1"># Show the plot.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p>Here is the output:</p>
<figure class="align-center">
<img alt="../_images/32.png" src="../_images/32.png" />
</figure>
<p>The histogram of the residuals are approximately normally distributed, which supports that the normality assumption is met for this model.The residuals in the Q-Q plot form a straight line, further supporting that the normality assumption is met.</p>
<p><strong>3. Homoscedasticity</strong></p>
<p>The homoscedasticity (constant variance) assumption is that the residuals have a constant variance for all values of X.</p>
<p>Check that this assumption is not violated by creating a scatterplot with the fitted values and residuals. Add a line at  𝑦=0 to visualize the variance of residuals above and below  𝑦=0.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a scatterplot with the fitted values from the model and the residuals.</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fittedvalues</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">resid</span><span class="p">)</span>

<span class="c1"># Set the x-axis label.</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Fitted Values&quot;</span><span class="p">)</span>

<span class="c1"># Set the y-axis label.</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Residuals&quot;</span><span class="p">)</span>

<span class="c1"># Set the title.</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Fitted Values v. Residuals&quot;</span><span class="p">)</span>

<span class="c1"># Add a line at y = 0 to visualize the variance of residuals above and below 0.</span>
<span class="n">fig</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Show the plot.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p>This is the output of the above lines:</p>
<figure class="align-center">
<img alt="../_images/33.png" src="../_images/33.png" />
</figure>
<p>The variance of the residuals is constant across all 𝑋. Thus, the assumption of homoscedasticity is met.</p>
<p>Display the OLS regression results from the fitted model object, which includes information about the dataset, model fit, and coefficients by running this line:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Display the model_results defined above.</span>
<span class="n">model_results</span>
</pre></div>
</div>
<p>Here is the output:</p>
<figure class="align-center">
<img alt="../_images/34.png" src="../_images/34.png" />
</figure>
<p>The R-squared on the top right of the output above measures the proportion of variation in the dependent variable (Y) explained by the independent variable (X). Using TV as X results in a simple linear regression model with  𝑅2=0.999. In other words, TV explains  99.9% of the variation in Sales.
It should be noted that The R-squared value will depend on the variable selected for X.</p>
<p>When TV is used as the independent variable X, the coefficient for the Intercept is -0.1263 and the coefficient for TV is 3.5614.When TV is used as the independent variable X, the linear equation is:</p>
<p>𝑌=Intercept+Slope∗𝑋</p>
<p>Sales (in millions)=Intercept+Slope∗TV (in millions)
Sales (in millions)=−0.1263+3.5614∗TV (in millions)</p>
<p>With regards to the above equation we can conclude when TV is used as the independent variable X, an increase of one million dollars for the TV promotional budget results in an estimated 3.5614 million dollars more in sales.</p>
<p>In addition, model coefficients are estimated. This means there is an amount of uncertainty in the estimate. A p-value and  95% confidence interval are provided with each coefficient to quantify the uncertainty for that coefficient estimate.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When TV is used as the independent variable, it has a p-value of  0.000 and a  95% confidence interval of [3.558,3.565]. This means there is a  95% chance the interval  [3.558,3.565] contains the true parameter value of the slope. These results indicate little uncertainty in the estimation of the slope of X. Therefore, the business can be confident in the impact TV has on Sales.</p>
</div>
<p>Finally we can conclude that:</p>
<p><span class="math notranslate nohighlight">\(\bullet\)</span> The linear regression model estimates that 99.9% of the variation in sales is explained by the TV promotional budget. In other words, nearly all of the variation in sales can be explained by the TV promotional budget alone, making TV an excellent predictor of sales.</p>
<p><span class="math notranslate nohighlight">\(\bullet\)</span> Among the three available promotion types (TV, radio, and social media), TV has the strongest positive linear relationship with sales. According to the model, an increase of one million dollars for the TV promotional budget will result in an estimated 3.5614 million dollars more in sales. This is a very confident estimate, as the p-value for this coefficient estimate is small. Thus, the business should prioritize increasing the TV promotional budget over the radio and social media promotional budgets to increase sales.</p>
<p><span class="math notranslate nohighlight">\(\bullet\)</span> The interval (3.558 million, 3.565 million) has a 95% probability of containing the true estimate of the increase in sales for a one million dollar increase in the TV promotional budget. Therefore, the estimate provided in the previous bullet is very confident.</p>
</section>
<section id="multiple-linear-regression">
<h2>6.2. Multiple linear regression<a class="headerlink" href="#multiple-linear-regression" title="Permalink to this heading"></a></h2>
<p>multiple linear regression helps you estimate the linear relationship between one continuous dependent variable and two or more independent variables. This is a useful skill because it allows you to compare more than one variable to the variable you’re measuring.</p>
<p>In this new data sheet, each row corresponds to an independent marketing promotion where their business uses TV, social media, radio, and influencer promotions to increase sales. We want to conduct a multiple linear regression analysis to estimate sales from a combination of independent variables.</p>
<p>As usual, we need to import the required packages in the first step:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="nn">sm</span>
<span class="kn">from</span> <span class="nn">statsmodels.formula.api</span> <span class="kn">import</span> <span class="n">ols</span>
</pre></div>
</div>
<p>Then we load the data:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load the data.</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;marketing_sales_data.csv&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>The features in the data are:</p>
<p><span class="math notranslate nohighlight">\(\bullet\)</span> TV promotional budget (in “Low,” “Medium,” and “High” categories)
<span class="math notranslate nohighlight">\(\bullet\)</span> Social media promotional budget (in millions of dollars)
<span class="math notranslate nohighlight">\(\bullet\)</span> Radio promotional budget (in millions of dollars)
<span class="math notranslate nohighlight">\(\bullet\)</span> Sales (in millions of dollars)
<span class="math notranslate nohighlight">\(\bullet\)</span> Influencer size (in “Mega,” “Macro,” “Nano,” and “Micro” categories)</p>
<p>The initial actions we need to take include:</p>
<p><span class="math notranslate nohighlight">\(\bullet\)</span> Understanding which variables are present in the data
<span class="math notranslate nohighlight">\(\bullet\)</span> Reviewing the distribution of features, such as minimum, mean, and maximum values
<span class="math notranslate nohighlight">\(\bullet\)</span> Plotting the relationship between the independent and dependent variables to visualize which features have a linear relationship
<span class="math notranslate nohighlight">\(\bullet\)</span> Identifying issues with the data, such as incorrect values (e.g., typos) or missing values</p>
<p>We can create a pairplot to visualize the relationship between the continuous variable</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a pairplot of the data.</span>
<span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">data</span><span class="p">);</span>
</pre></div>
</div>
<p>Here is the out put:</p>
<figure class="align-center">
<img alt="../_images/35.png" src="../_images/35.png" />
</figure>
<p>According to the above graph, Radio and Social Media both appear to have linear relationships with Sales. Given this, Radio and Social Media may be useful as independent variables in a multiple linear regression model estimating Sales.</p>
<p>There are two categorical variables: TV and Influencer. To characterize the relationship between the categorical variables and Sales, find the mean Sales for each category in TV and the mean Sales for each category in Influence.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Calculate the mean sales for each TV category.</span>
<span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;TV&#39;</span><span class="p">)[</span><span class="s1">&#39;Sales&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>

<span class="c1"># Calculate the mean sales for each Influencer category .</span>
<span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;Influencer&#39;</span><span class="p">)[</span><span class="s1">&#39;Sales&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
</pre></div>
</div>
<p>This is the output:</p>
<figure class="align-center">
<img alt="../_images/36.png" src="../_images/36.png" />
</figure>
<p>The average Sales for High TV promotions is considerably higher than for Medium and Low TV promotions. TV may be a strong predictor of Sales. However, the categories for Influencer have different average Sales, but the variation is not substantial. Influencer may be a weak predictor of Sales.These results can be investigated further when fitting the multiple linear regression model.</p>
<p>This dataset contains rows with missing values. To correct this, drop all rows that contain missing data.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Drop rows that contain missing data and update the DataFrame.</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The ols() function doesn’t run when variable names contain a space. Check that the column names in data do not contain spaces and fix them, if needed.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Rename all columns in data that contain a space.</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;Social Media&#39;</span><span class="p">:</span> <span class="s1">&#39;Social_Media&#39;</span><span class="p">})</span>
</pre></div>
</div>
<p>Now we can fit a multiple linear regression model that predicts sales:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define the OLS formula.</span>
<span class="n">ols_formula</span> <span class="o">=</span> <span class="s1">&#39;Sales ~ C(TV) + Radio&#39;</span>
<span class="n">OLS</span> <span class="o">=</span> <span class="n">ols</span><span class="p">(</span><span class="n">formula</span> <span class="o">=</span> <span class="n">ols_formula</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">)</span>

<span class="c1"># Fit the model.</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">OLS</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="c1"># Save the results summary.</span>
<span class="n">model_results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>

<span class="c1"># Display the model results.</span>
<span class="n">model_results</span>
</pre></div>
</div>
<p>This is the output:</p>
<figure class="align-center">
<img alt="../_images/36.png" src="../_images/36.png" />
</figure>
<p>The most important conclusions could be listed as below:</p>
<p><span class="math notranslate nohighlight">\(\bullet\)</span> TV was selected, as the analysis above showed a strong relationship between the TV promotional budget and the average Sales.</p>
<p><span class="math notranslate nohighlight">\(\bullet\)</span> Radio was selected because the pairplot showed a strong linear relationship between Radio and Sales.</p>
<p><span class="math notranslate nohighlight">\(\bullet\)</span> Social Media was not selected because it did not increase model performance and it was later determined to be correlated with another independent variable: Radio.</p>
<p><span class="math notranslate nohighlight">\(\bullet\)</span> Influencer was not selected because it did not show a strong relationship to Sales in the analysis above.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For multiple linear regression, there is an additional assumption added to the four simple linear regression assumptions: multicollinearity.</p>
</div>
<p>The assumption for the linear regression could be checked as below:</p>
<p><strong>1. Linearity</strong></p>
<p>We can create scatterplots to compare the continuous independent variable(s) with Sales to check the linearity assumption. In this regards, we can use the pairplot to verify the linearity assumption or create new scatterplots comparing the variables of interest.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a scatterplot for each independent variable and the dependent variable.</span>
<span class="c1"># Create a 1x2 plot figure.</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>

<span class="c1"># Create a scatterplot between Radio and Sales.</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;Radio&#39;</span><span class="p">],</span> <span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;Sales&#39;</span><span class="p">],</span><span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span>

<span class="c1"># Set the title of the first plot.</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Radio and Sales&quot;</span><span class="p">)</span>

<span class="c1"># Create a scatterplot between Social Media and Sales.</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;Social_Media&#39;</span><span class="p">],</span> <span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;Sales&#39;</span><span class="p">],</span><span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;c&#39;</span><span class="p">)</span>

<span class="c1"># Set the title of the second plot.</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Social Media and Sales&quot;</span><span class="p">)</span>

<span class="c1"># Set the xlabel of the second plot.</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Social Media&quot;</span><span class="p">)</span>

<span class="c1"># Use matplotlib&#39;s tight_layout() function to add space between plots for a cleaner appearance.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p>Here is the output:</p>
<figure class="align-center">
<img alt="../_images/38.png" src="../_images/38.png" />
</figure>
<p>The linearity assumption holds for Radio, as there is a clear linear relationship in the scatterplot between Radio and Sales. Social Media was not included in the multiple linear regression model above, but it does appear to have a linear relationship with Sales.</p>
<p><strong>2. Independence</strong></p>
<p>The independent observation assumption states that each observation in the dataset is independent. As each marketing promotion (i.e., row) is independent from one another, the independence assumption hols true.</p>
<p><strong>3. Normality</strong></p>
<p>The normality assumption could e checked using histogram of the residuals or Q-Q plot of the residuals:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Calculate the residuals.</span>
<span class="n">residuals</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">resid</span>

<span class="c1"># Create a 1x2 plot figure.</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>

<span class="c1"># Create a histogram with the residuals.</span>
<span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">residuals</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="c1"># Set the x label of the residual plot.</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Residual Value&quot;</span><span class="p">)</span>

<span class="c1"># Set the title of the residual plot.</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Histogram of Residuals&quot;</span><span class="p">)</span>

<span class="c1"># Create a Q-Q plot of the residuals.</span>
<span class="n">sm</span><span class="o">.</span><span class="n">qqplot</span><span class="p">(</span><span class="n">residuals</span><span class="p">,</span> <span class="n">line</span><span class="o">=</span><span class="s1">&#39;s&#39;</span><span class="p">,</span><span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

<span class="c1"># Set the title of the Q-Q plot.</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Normal QQ Plot&quot;</span><span class="p">)</span>

<span class="c1"># Use matplotlib&#39;s tight_layout() function to add space between plots for a cleaner appearance.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>

<span class="c1"># Show the plot.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p>Here is the output:</p>
<figure class="align-center">
<img alt="../_images/39.png" src="../_images/39.png" />
</figure>
<p>According to the above graph, the histogram of the residuals are approximately normally distributed, which supports that the normality assumption is met for this model. The residuals in the Q-Q plot form a straight line, further supporting that this assumption is met.</p>
<p><strong>3. Constant variance</strong></p>
<p>We should create a scatterplot with the fitted values and residuals. Add a line at  𝑦=0 to visualize the variance of residuals above and below  𝑦=0:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a scatterplot with the fitted values from the model and the residuals.</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fittedvalues</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">resid</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">)</span>

<span class="c1"># Set the x axis label.</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Fitted Values&quot;</span><span class="p">)</span>

<span class="c1"># Set the y axis label.</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Residuals&quot;</span><span class="p">)</span>

<span class="c1"># Set the title.</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Fitted Values v. Residuals&quot;</span><span class="p">)</span>

<span class="c1"># Add a line at y = 0 to visualize the variance of residuals above and below 0.</span>
<span class="n">fig</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Show the plot.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p>Here is the output graph:</p>
<figure class="align-center">
<img alt="../_images/40.png" src="../_images/40.png" />
</figure>
<p>The fitted values are in three groups because the categorical variable is dominating in this model, meaning that TV is the biggest factor that decides the sales.However, the variance where there are fitted values is similarly distributed, validating that the assumption is met.</p>
<p><strong>4. No multicollinearity</strong></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The no multicollinearity assumption states that no two independent variables can be highly correlated with each other.Two common ways to check for multicollinearity are to:</p>
<blockquote>
<div><p><span class="math notranslate nohighlight">\(\bullet\)</span> Create scatterplots to show the relationship between pairs of independent variables</p>
<p><span class="math notranslate nohighlight">\(\bullet\)</span> Use the variance inflation factor to detect multicollinearity</p>
</div></blockquote>
</div>
<p>To check the variance inflation factor:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Calculate the variance inflation factor (optional).</span>
<span class="c1"># Import variance_inflation_factor from statsmodels.</span>
<span class="kn">from</span> <span class="nn">statsmodels.stats.outliers_influence</span> <span class="kn">import</span> <span class="n">variance_inflation_factor</span>

<span class="c1"># Create a subset of the data with the continous independent variables.</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="p">[[</span><span class="s1">&#39;Radio&#39;</span><span class="p">,</span><span class="s1">&#39;Social_Media&#39;</span><span class="p">]]</span>

<span class="c1"># Calculate the variance inflation factor for each variable.</span>
<span class="n">vif</span> <span class="o">=</span> <span class="p">[</span><span class="n">variance_inflation_factor</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span>

<span class="c1"># Create a DataFrame with the VIF results for the column names in X.</span>
<span class="n">df_vif</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">vif</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;VIF&#39;</span><span class="p">])</span>

<span class="c1"># Display the VIF results.</span>
<span class="n">df_vif</span>
</pre></div>
</div>
<p>Where the variance inflation factor is found equal to 4.93238 for both <strong>Radio</strong> and <strong>Social_Media</strong>.</p>
<p>The model above only has one continuous independent variable (Only the Radio is continuous while TV is NOT), meaning there are no multicollinearity issues.If a model used both Radio and Social_Media as predictors, there would be a moderate linear relationship between Radio and Social_Media that violates the multicollinearity assumption.</p>
<p>According to the summary of the model presented before:</p>
<p>Using TV and Radio as the independent variables results in a multiple linear regression model with  <span class="math notranslate nohighlight">\(R^{2}=0.904\)</span>. In other words, the model explains  90.4% of the variation in Sales. This makes the model an excellent predictor of Sales.</p>
<p>When TV and Radio are used to predict Sales, the model coefficients are:</p>
<p><span class="math notranslate nohighlight">\(\bullet\)</span> <span class="math notranslate nohighlight">\(\beta_{0}=218.5261\)</span></p>
<p><span class="math notranslate nohighlight">\(\bullet\)</span> <span class="math notranslate nohighlight">\(\beta_{𝑇𝑉𝐿𝑜𝑤}=−154.2971\)</span></p>
<p><span class="math notranslate nohighlight">\(\bullet\)</span> <span class="math notranslate nohighlight">\(\beta_{T𝑉𝑀𝑒𝑑𝑖𝑢𝑚}=−75.3120\)</span></p>
<p><span class="math notranslate nohighlight">\(\bullet\)</span> <span class="math notranslate nohighlight">\(\beta_{𝑅𝑎𝑑𝑖𝑜}=2.9669\)</span></p>
<p>Now we can define the Sales as below:</p>
<div class="math notranslate nohighlight" id="eq-115">
<span id="equation-eq-115"></span><span class="eqno">(104)<a class="headerlink" href="#eq-115" title="Permalink to this equation"></a></span>\[ Sales= \beta_{0} + \beta_{𝑇𝑉𝐿𝑜𝑤} * X_{𝑇𝑉𝐿𝑜𝑤} +\beta_{𝑀𝑒𝑑𝑖𝑢𝑚} * X_{𝑇𝑉𝑀𝑒𝑑𝑖𝑢𝑚} + \beta_{𝑅𝑎𝑑𝑖𝑜} * X_{𝑅𝑎𝑑𝑖𝑜}\]</div>
<p>The default TV category for the model is High since there are coefficients for the other two TV categories, Medium and Low. Because the coefficients for the Medium and Low TV categories are negative, that means the average of sales is lower for Medium or Low TV categories compared to the High TV category when Radio is at the same level.</p>
<p>The p-value for all coefficients is  0.000, meaning all coefficients are statistically significant at  𝑝=0.05. The 95% confidence intervals for each coefficient should be reported when presenting results.</p>
<p>For example, there is a  95% chance that the interval  [−163.979,−144.616] contains the true parameter of the slope of  <span class="math notranslate nohighlight">\(\beta_{𝑇𝑉𝐿𝑜𝑤}\)</span>, which is the estimated difference in promotion sales when a Low TV promotion is chosen instead of a High TV promotion.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Beta coefficients allow you to estimate the magnitude and direction (positive or negative) of the effect of each independent variable on the dependent variable. The coefficient estimates can be converted to explainable insights, such as the connection between an increase in TV promotional budgets and sales mentioned above.</p>
</div>
</section>
<section id="hypothesis-testing">
<h2>6.3. Hypothesis testing<a class="headerlink" href="#hypothesis-testing" title="Permalink to this heading"></a></h2>
<p>Analysis of variance (commonly called ANOVA) is a group of statistical techniques that test the difference of means among three or more groups. It’s a powerful tool for determining whether population means are different across groups.</p>
<p>In the dataset used in this section, each row corresponds to an independent marketing promotion and there are 4 factors including TV, social media, radio, and influencer promotions to increase sales. We want to know if sales are significantly different among various <strong>categorical variables</strong> including TV and influencer promotion types.
In this regards, a one-way ANOVA test will be used to determine if there is a statistically significant difference in sales among groups.
Here are the steps we should take:</p>
<p><span class="math notranslate nohighlight">\(\bullet\)</span> Using plots and descriptive statistics to select a categorical independent variable</p>
<p><span class="math notranslate nohighlight">\(\bullet\)</span> Creating and fitting a linear regression model with the selected categorical independent variable</p>
<p><span class="math notranslate nohighlight">\(\bullet\)</span> Checking model assumptions</p>
<p><span class="math notranslate nohighlight">\(\bullet\)</span> Performing and interpreting a one-way ANOVA test</p>
<p><span class="math notranslate nohighlight">\(\bullet\)</span> Comparing pairs of groups using an ANOVA post hoc test</p>
<p><span class="math notranslate nohighlight">\(\bullet\)</span> Interpreting model outputs and communicating the results to nontechnical stakeholders</p>
<p>First we need to import the required packages:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import libraries and packages.</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="nn">sm</span>
<span class="kn">from</span> <span class="nn">statsmodels.formula.api</span> <span class="kn">import</span> <span class="n">ols</span>
<span class="kn">from</span> <span class="nn">statsmodels.stats.multicomp</span> <span class="kn">import</span> <span class="n">pairwise_tukeyhsd</span>
</pre></div>
</div>
<p>The we load our dataset:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load the data.</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;marketing_sales_data.csv&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>The features in the data are:</p>
<p><strong>1.</strong> TV promotion budget (in Low, Medium, and High categories)</p>
<p><strong>2.</strong> Social media promotion budget (in millions of dollars)</p>
<p><strong>3.</strong> Radio promotion budget (in millions of dollars)</p>
<p><strong>4.</strong> Sales (in millions of dollars)</p>
<p><strong>5.</strong> Influencer size (in Mega, Macro, Nano, and Micro categories)</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This is important to perform exploratory data analysis (EDA) before constructing a linear regression model for the below purposes:</p>
<blockquote>
<div><p><span class="math notranslate nohighlight">\(\bullet\)</span> To understand which variables are present in the data</p>
<p><span class="math notranslate nohighlight">\(\bullet\)</span> To consider the distribution of features, such as minimum, mean, and maximum values</p>
<p><span class="math notranslate nohighlight">\(\bullet\)</span> To plot the relationship between the independent and dependent variables and visualize which features have a linear relationship</p>
<p><span class="math notranslate nohighlight">\(\bullet\)</span> To identify issues with the data, such as incorrect or missing values.</p>
</div></blockquote>
</div>
<p>Now we can use a boxplot to determine how Sales vary based on the TV promotion budget category:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a boxplot with TV and Sales.</span>
<span class="n">my_pal</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;Low&quot;</span><span class="p">:</span> <span class="s2">&quot;c&quot;</span><span class="p">,</span> <span class="s2">&quot;Medium&quot;</span><span class="p">:</span> <span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="s2">&quot;High&quot;</span><span class="p">:</span><span class="s2">&quot;m&quot;</span><span class="p">}</span>
<span class="n">sns</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="s2">&quot;TV&quot;</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="s2">&quot;Sales&quot;</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">,</span><span class="n">palette</span><span class="o">=</span><span class="n">my_pal</span><span class="p">);</span>
</pre></div>
</div>
<p>Here is the output of the above graph:</p>
<figure class="align-center">
<img alt="../_images/41.png" src="../_images/41.png" />
</figure>
<p>There is considerable variation in Sales across the TV groups. The significance of these differences can be tested with a one-way ANOVA.</p>
<p>Now, we can plot the same graph for the Influencer category:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a boxplot with Influencer and Sales.</span>
<span class="n">sns</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="s2">&quot;Influencer&quot;</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="s2">&quot;Sales&quot;</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">);</span>
</pre></div>
</div>
<p>The output of the above is presented here:</p>
<figure class="align-center">
<img alt="../_images/42.png" src="../_images/42.png" />
</figure>
<p>According to the above graph, there is some variation in Sales across the Influencer groups, but it may not be significant.</p>
<p>It should be noted that the dataset may contain missing rows. To correct this, we should drop these rows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Drop rows that contain missing data and update the DataFrame.</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>


<span class="c1"># Confirm the data contain no missing values.</span>
<span class="n">data</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>Now we want to fit a linear regression model that predicts Sales using one of the independent <strong>categorical</strong> variables in data:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define the OLS formula.</span>
<span class="n">ols_formula</span> <span class="o">=</span> <span class="s1">&#39;Sales ~ C(TV)&#39;</span>

<span class="c1"># Create an OLS model.</span>
<span class="n">OLS</span> <span class="o">=</span> <span class="n">ols</span><span class="p">(</span><span class="n">formula</span> <span class="o">=</span> <span class="n">ols_formula</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">)</span>

<span class="c1"># Fit the model.</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">OLS</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="c1"># Save the results summary.</span>
<span class="n">model_results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>

<span class="c1"># Display the model results.</span>
<span class="n">model_results</span>
</pre></div>
</div>
<p>The output is here:</p>
<figure class="align-center">
<img alt="../_images/43.png" src="../_images/43.png" />
</figure>
<p>TV was selected as the analysis above showed a strong relationship between the TV promotion budget and the average Sales. Influencer was not selected because it did not show a strong relationship to Sales in the analysis.</p>
<p>Now we should check the model assumptions:</p>
<p><strong>1. Linearity</strong></p>
<p>Because your model does not have any continuous independent variables, the linearity assumption is not required.</p>
<p><strong>2. Independency</strong></p>
<p>The independent observation assumption states that each observation in the dataset is independent. As each marketing promotion (row) is independent from one another, the independence assumption is not violated.</p>
<p><strong>3. Normality</strong></p>
<p>To check the normality we can plot a histogram or create a Q-Q plot:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Calculate the residuals.</span>
<span class="n">residuals</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">resid</span>

<span class="c1"># Create a 1x2 plot figure.</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>

<span class="c1"># Create a histogram with the residuals.</span>
<span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">residuals</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;m&#39;</span><span class="p">)</span>

<span class="c1"># Set the x label of the residual plot.</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Residual Value&quot;</span><span class="p">)</span>

<span class="c1"># Set the title of the residual plot.</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Histogram of Residuals&quot;</span><span class="p">)</span>

<span class="c1"># Create a QQ plot of the residuals.</span>
<span class="n">sm</span><span class="o">.</span><span class="n">qqplot</span><span class="p">(</span><span class="n">residuals</span><span class="p">,</span> <span class="n">line</span><span class="o">=</span><span class="s1">&#39;s&#39;</span><span class="p">,</span><span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

<span class="c1"># Set the title of the QQ plot.</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Normal QQ Plot&quot;</span><span class="p">)</span>

<span class="c1"># Use matplotlib&#39;s tight_layout() function to add space between plots for a cleaner appearance.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>

<span class="c1"># Show the plot.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p>Here is the output:</p>
<figure class="align-center">
<img alt="../_images/44.png" src="../_images/44.png" />
</figure>
<p>According to the above graph, there is reasonable concern that the normality assumption is not met when TV is used as the independent variable predicting Sales. The normal q-q forms an ‘S’ that deviates off the red diagonal line, which is not desired behavior.</p>
<p><strong>4. Constant variance (homoscedasticity)</strong></p>
<p>To check this condition we can make a scatterplot (Residuals vs Fitted Values):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a scatter plot with the fitted values from the model and the residuals.</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fittedvalues</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">resid</span><span class="p">)</span>

<span class="c1"># Set the x axis label</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Fitted Values&quot;</span><span class="p">)</span>

<span class="c1"># Set the y axis label</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Residuals&quot;</span><span class="p">)</span>

<span class="c1"># Set the title</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Fitted Values v. Residuals&quot;</span><span class="p">)</span>

<span class="c1"># Add a line at y = 0 to visualize the variance of residuals above and below 0.</span>
<span class="n">fig</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Show the plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p>This is the output:</p>
<figure class="align-center">
<img alt="../_images/45.png" src="../_images/45.png" />
</figure>
<p>Based on the above graph, the variance where there are fitted values is similarly distributed, validating that the constant variance assumption is met.</p>
<p>Using TV as the independent variable results in a linear regression model with  <span class="math notranslate nohighlight">\(R^{2}=0.871\)</span>. In other words, the model explains  86.1% of the variation in Sales. This makes the model an effective predictor of Sales.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The default TV category for the model is High, because there are coefficients for the other two TV categories, Medium and Low. According to the model, Sales with a Medium or Low TV category are lower on average than Sales with a High TV category. For example, the model predicts that a Low TV promotion would be 209.8691 (in millions of dollars) lower in Sales on average than a High TV promotion.</p>
<p>The p-value for all coefficients is  0.000 , meaning all coefficients are statistically significant at  𝑝=0.05. The 95% confidence intervals for each coefficient should be reported when presenting results to stakeholders. For instance, there is a  95% chance the interval  [−216.535,−203.203] contains the true parameter of the slope of  𝛽𝑇𝑉𝐿𝑜𝑤 , which is the estimated difference in promotion sales when a Low TV promotion is chosen instead of a High TV promotion.</p>
</div>
<p>After fitting the model, we can run a one-way ANOVA test to determine whether there is a statistically significant difference in Sales among groups:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create an one-way ANOVA table for the fit model.</span>
<span class="n">sm</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">anova_lm</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">typ</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>The output is presented here:</p>
<figure class="align-center">
<img alt="../_images/46.png" src="../_images/46.png" />
</figure>
<p>In this example:</p>
<p><span class="math notranslate nohighlight">\(\bullet\)</span> The null hypothesis is that there is no difference in Sales based on the TV promotion budget.</p>
<p><span class="math notranslate nohighlight">\(\bullet\)</span> The alternative hypothesis is that there is a difference in Sales based on the TV promotion budget.</p>
<p>The F-test statistic is 1916.75 and the p-value is  1.38E−253 (i.e., very small). Because the p-value is less than 0.05, you would reject the null hypothesis that there is no difference in Sales based on the TV promotion budget.</p>
<p><strong>ANOVA post hoc test</strong></p>
<p>We can apply ANOVA post hoc tests such as the Tukey’s HSD post hoc test to compare if there is a significant difference between each pair of categories for TV.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Perform the Tukey&#39;s HSD post hoc test.</span>
<span class="n">tukey_oneway</span> <span class="o">=</span> <span class="n">pairwise_tukeyhsd</span><span class="p">(</span><span class="n">endog</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;Sales&quot;</span><span class="p">],</span> <span class="n">groups</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;TV&quot;</span><span class="p">])</span>

<span class="c1"># Display the results</span>
<span class="n">tukey_oneway</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
<p>Here is the output:</p>
<figure class="align-center">
<img alt="../_images/46.png" src="../_images/46.png" />
</figure>
<p>According to the above graph, The first row, which compares the High and Low TV groups, indicates that you can reject the null hypothesis that there is no significant difference between the Sales of these two groups.</p>
<p>We can also reject the null hypotheses for the two other pairwise comparisons that compare High to Medium and Low to Medium.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A post hoc test was conducted to determine which TV groups are different and how many are different from each other. This provides more detail than the <strong>one-way ANOVA</strong> results, <strong>which can at most determine that at least one group is different</strong>. Further, using the Tukey HSD controls for the increasing probability of incorrectly rejecting a null hypothesis from peforming multiple tests.</p>
</div>
<p>The following are estimates for the average difference between each pair of TV promotions:</p>
<p><span class="math notranslate nohighlight">\(\bullet\)</span> Estimated average difference between High and Low TV promotions: $209.87 million (with 95% confidence that the exact value for this average difference is between 201.89 and 216.84 million dollars).</p>
<p><span class="math notranslate nohighlight">\(\bullet\)</span> Estimated average difference between High and Medium TV promotions: $105.50 million (with 95% confidence that the exact value for this average difference is between 96.56 and 113.43 million dollars).</p>
<p><span class="math notranslate nohighlight">\(\bullet\)</span> Estimated average difference between Medium and Low TV promotions: $104.37 million (with 95% confidence that the exact value for this average difference is between 96.83 and 111.92 million dollars).</p>
<p>Finally, The linear regression model estimating Sales from TV had an R-squared of $0.871, making it a fairly accurate estimator. The model showed a statistically significant relationship between the TV promotion budget and Sales. The model estimated the following relationships:</p>
<p><span class="math notranslate nohighlight">\(\bullet\)</span> Using a high TV promotion budget instead of a medium TV promotion budget increased sales by 105.4952 million dollars (95% CI - 98.859, 112.131 million dollars).</p>
<p><span class="math notranslate nohighlight">\(\bullet\)</span> Using a high TV promotion budget instead of a low TV promotion budget increased sales by 209.8691 million dollars (95% CI - 203.203 million, 216.535 million dollars).</p>
</section>
<section id="logistic-regression">
<h2>6.4. Logistic regression<a class="headerlink" href="#logistic-regression" title="Permalink to this heading"></a></h2>
<p>In this section we will conduct a bionomial logistic regression.</p>
<p><strong>Bionomial Logistic Regression</strong>: This is a technique that models probability of an observation falling into one of two categories based on one or more independent variable. The below figure, compares the linear regression and logistic regression models:</p>
<figure class="align-center">
<img alt="../_images/49.png" src="../_images/49.png" />
</figure>
<p>The data for this section come from an airline. We are interested in knowing if a better in-flight entertainment experience leads to higher customer satisfaction. So we will construct and evaluate a model that predicts whether a future customer would be satisfied with their services given previous customer feedback about their flight experience.</p>
<p>The data for this activity is for a sample size of 129,880 customers. It includes data points such as class, flight distance, and in-flight entertainment, among others. The goal is to utilize a binomial logistic regression model to help the airline model and better understand this data.</p>
<p>Here are the steps we should take:</p>
<p><span class="math notranslate nohighlight">\(\bullet\)</span> Importing packages and loading data</p>
<p><span class="math notranslate nohighlight">\(\bullet\)</span> Exploring the data and completing the cleaning process</p>
<p><span class="math notranslate nohighlight">\(\bullet\)</span> Building a binomial logistic regression model</p>
<p><span class="math notranslate nohighlight">\(\bullet\)</span> Evaluating a binomial logistic regression model using a confusion matrix</p>
<p>First we need to import the required packages:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Standard operational package imports.</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1"># Important imports for preprocessing, modeling, and evaluation.</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">import</span> <span class="nn">sklearn.metrics</span> <span class="k">as</span> <span class="nn">metrics</span>

<span class="c1"># Visualization package imports.</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
</pre></div>
</div>
<p>Next we should load the data:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">df_original</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;Invistico_Airline.csv&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>We need to prepare the data in way that they are suitable for binomial logistic regression analysis. Here are actions we should take regarding the data:</p>
<p><span class="math notranslate nohighlight">\(\bullet\)</span> Exploring the data</p>
<p><span class="math notranslate nohighlight">\(\bullet\)</span> Checking for missing values</p>
<p><span class="math notranslate nohighlight">\(\bullet\)</span> Encoding the data</p>
<p><span class="math notranslate nohighlight">\(\bullet\)</span> Renaming a column</p>
<p><span class="math notranslate nohighlight">\(\bullet\)</span> Creating the training and testing data</p>
<p>We can extract the information explaining how many customers in the dataset are satisfied before modeling:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">df_original</span><span class="p">[</span><span class="s1">&#39;satisfaction&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">dropna</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<p>Based on the output of the above line we can see there were 71,087 satisfied customers and 58,793 dissatisfied customers. In other words, 54.7 percent (71,087/129,880) of customers were satisfied.</p>
<p>An assumption of logistic regression models is that there are no missing values. Check for missing values in the rows of the data.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">df_original</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
<p>There are only 393 missing values out of the total of 129,880, so these are a small percentage of the total. This column might impact the relationship between entertainment and satisfaction. Drop the rows with missing values and save the resulting pandas DataFrame in a variable named df_subset:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">df_subset</span> <span class="o">=</span> <span class="n">df_original</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>If you want to create a plot (sns.regplot) of your model to visualize results later, the independent variable Inflight entertainment cannot be “of type int” and the dependent variable satisfaction cannot be “of type object. “Make the Inflight entertainment” column “of type float.”</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">df_subset</span> <span class="o">=</span> <span class="n">df_subset</span><span class="o">.</span><span class="n">astype</span><span class="p">({</span><span class="s2">&quot;Inflight entertainment&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">})</span>
</pre></div>
</div>
<p>In the next step, we need to convert the categorical column satisfaction into numeric through one-hot encoding:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">df_subset</span><span class="p">[</span><span class="s1">&#39;satisfaction&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="s1">&#39;first&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df_subset</span><span class="p">[[</span><span class="s1">&#39;satisfaction&#39;</span><span class="p">]])</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
</pre></div>
</div>
<p>To examine what one-hot encoding did to the DataFrame, output the first 100 rows of df_subset:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">df_subset</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
<p>Under the satisfaction column, if the customer is satisfied, it will be appear as 1.0 and if is NOT satisfied it will appear as 0.0.</p>
<p>Next we put 70% of the data into a training set and the remaining 30% into a testing set. Create an X and y DataFrame with only the necessary variables (We want to use inflight entertainment as the only independent variable):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">df_subset</span><span class="p">[[</span><span class="s2">&quot;Inflight entertainment&quot;</span><span class="p">]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_subset</span><span class="p">[</span><span class="s2">&quot;satisfaction&quot;</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
<p>Now we build a logistic regression model and fit the model to the training data:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">clf</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
<p>Now we create a plot of your model to visualize results using the seaborn package:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">regplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;Inflight entertainment&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;satisfaction&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df_subset</span><span class="p">,</span> <span class="n">logistic</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">ci</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;m&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>Here is the output:</p>
<figure class="align-center">
<img alt="../_images/48.png" src="../_images/48.png" />
</figure>
<p>The graph seems to indicate that the higher the inflight entertainment value, the higher the customer satisfaction, though this is currently not the most informative plot. The graph currently doesn’t provide much insight into the data points, as Inflight entertainment is categorical.</p>
<p><strong>Predict the outcome for the test dataset</strong></p>
<p>Now we input the holdout dataset into the predict function to get the predicted labels from the model.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Save predictions.</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When you decide to reject or fail to reject the null hypothesis, there are four possible outcomes–two represent correct choices, and two represent errors. You can:</p>
<blockquote>
<div><p><span class="math notranslate nohighlight">\(\bullet\)</span> Reject the null hypothesis when it’s actually true (Type I error) (<strong>False Positive</strong>)</p>
<p><span class="math notranslate nohighlight">\(\bullet\)</span> Reject the null hypothesis when it’s actually false (Correct) (<strong>True Positive</strong>)</p>
<p><span class="math notranslate nohighlight">\(\bullet\)</span> Fail to reject the null hypothesis when it’s actually true (Correct) (<strong>True Negative</strong>)</p>
<p><span class="math notranslate nohighlight">\(\bullet\)</span> Fail to reject the null hypothesis when it’s actually false (Type II error) (<strong>False Negative</strong>)</p>
</div></blockquote>
</div>
<p>This is clarified more in details in this figure:</p>
<figure class="align-center">
<img alt="../_images/50.png" src="../_images/50.png" />
</figure>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>There are three metrics that we use to evaluate the model prediction including:</p>
<blockquote>
<div><p><span class="math notranslate nohighlight">\(\bullet\)</span> <strong>Precision:</strong> Proportion of the positive prediction that were actually positive = <span class="math notranslate nohighlight">\(\frac {True Positive}{True Positive+False Positive}\)</span></p>
<p><span class="math notranslate nohighlight">\(\bullet\)</span> <strong>Recall:</strong> Proportion of the positives that the model was able to identify correctly = <span class="math notranslate nohighlight">\(\frac {True Positive}{True Positive+False Negative}\)</span></p>
<p><span class="math notranslate nohighlight">\(\bullet\)</span> <strong>Accuracy:</strong> Proportion of the data points that were categorized correctly = <span class="math notranslate nohighlight">\(\frac {True Positive+True Negative}{Total Predictions}\)</span></p>
</div></blockquote>
</div>
<p>We can print out the model’s accuracy, precision, recall, and F1 score:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy:&quot;</span><span class="p">,</span> <span class="s2">&quot;</span><span class="si">%.6f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">metrics</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Precision:&quot;</span><span class="p">,</span> <span class="s2">&quot;</span><span class="si">%.6f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">metrics</span><span class="o">.</span><span class="n">precision_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Recall:&quot;</span><span class="p">,</span> <span class="s2">&quot;</span><span class="si">%.6f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">metrics</span><span class="o">.</span><span class="n">recall_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>
</div>
<p>The output is:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">Accuracy</span><span class="p">:</span> <span class="mf">0.801529</span>
<span class="n">Precision</span><span class="p">:</span> <span class="mf">0.816142</span>
<span class="n">Recall</span><span class="p">:</span> <span class="mf">0.821530</span>
</pre></div>
</div>
<p><strong>Produce a confusion matrix</strong></p>
<p>Confusion matrix is a graphical representation of how accurate a classified is at predicting the lables for a categorical variable. The confusion matrix is shown in this figure:</p>
<figure class="align-center">
<img alt="../_images/51.png" src="../_images/51.png" />
</figure>
<p>Now we want to know the types of errors made by an algorithm. To obtain this information, produce a confusion matrix:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">cm</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">classes_</span><span class="p">)</span>
<span class="n">disp</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">ConfusionMatrixDisplay</span><span class="p">(</span><span class="n">confusion_matrix</span> <span class="o">=</span> <span class="n">cm</span><span class="p">,</span><span class="n">display_labels</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">classes_</span><span class="p">)</span>
<span class="n">disp</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</pre></div>
</div>
<p>Here is the output:</p>
<figure class="align-center">
<img alt="../_images/52.png" src="../_images/52.png" />
</figure>
<p>The lower left and top right corners are both under 4,000, which are relatively low numbers. Based on what we know from the data and interpreting the matrix, it’s clear that these numbers relate to false positives and false negatives.Additionally, the other two quadrants—the true positives and true negatives—are both high numbers above 13,000.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Using more than a single independent variable in the model training process could improve model performance. This is because other variables, like Departure Delay in Minutes, seem like they could potentially influence customer satisfaction.</p>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="Statistical%20Analysis.html" class="btn btn-neutral float-left" title="5. Statistical Analysis" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="ML.html" class="btn btn-neutral float-right" title="7. Fundamentals of Machine Learning" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Jafar Arash Mehr.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>