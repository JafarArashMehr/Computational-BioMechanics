

**5. Statistical Analysis**
================================================

.. note:: 

    All of required CSV files are available in the folder: **Statistics.txt** 

5.1. Descriptive statistics
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

In this chapter we have data from the United States Environmental Protection Agency (EPA). We want to analyze data on air quality. The data includes information from more than 200 sites, identified by state, county, city, and local site names. You will use Python functions to gather statistics about air quality.

First we need to import the relevant Python libraries `pandas` and `numpy`.

.. code-block:: python

        import pandas as pd
	import numpy as np


Load the dataset into a DataFrame. The dataset provided is in the form of a .csv file named c4_epa_air_quality.csv (the csv files are available in the GitHub)



Then we canlLoad data from the .csv file into a DataFrame and save in a variable.


.. code-block:: python

	epa_data = pd.read_csv("c4_epa_air_quality.csv", index_col = 0)


To understand how the dataset is structured, display the first 10 rows of the data.



.. code-block:: python

	epa_data.head(10)

Here is the output:

.. figure:: PNG/23.png
   :align: center

   Information of the first 10 rows of the data



Now, get a table that contains some descriptive statistics about the data.



.. code-block:: python

	epa_data.describe()


Here is the output:

.. figure:: PNG/24.png
   :align: center




From the above data, we can see that 25th percentile for the aqi column is 2. This means that 25% of the aqi values in the data are below 2 parts per million.in addition, the 75th percentile for the aqi column is 9. This means that 75% of the aqi values in the data are below 9 parts per million


Now get some descriptive statistics about the states in the data.


.. code-block:: python

	epa_data["state_name"].describe()


.. figure:: PNG/25.png
   :align: center

   


There are 260 state values, and 52 of them are unique. California is the most commonly occurring state in the data, with a frequency of 65.



Now, compute the mean value from the aqi column.

.. code-block:: python

	np.mean(epa_data["aqi"])


This means that the average aqi from the data is approximately 5.76 parts per million.
 
Now, compute the standard deviation for the aqi column:

.. code-block:: python

	np.std(epa_data["aqi"], ddof=1)


The standard deviation for the aqi column is approximately 7.05 (rounding to 2 decimal places here). This is a measure of how spread out the aqi values are in the data.

75% of the AQI values in the data are below 9 parts per million, which is the standard for healthy air quality levels in terms of carbon monoxide.
Funding should be allocated for further investigation of the regions with unhealthy levels of carbon monoxide in order to learn how to improve the conditions.



5.2. Data sampling
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


we will be using numpy, pandas, scipy stats, and statsmodels for operations, and matplotlib for plotting.

.. code-block:: python

	import numpy as np
	import pandas as pd
	import matplotlib.pyplot as plt
	from scipy import stats
	import statsmodels.api as sm

We want  analyze data on the literacy rate for each district. First we need to read the data and then use the dropna() method to remove the rows that contains NULL values.


.. code-block:: python

	education_districtwise = pd.read_csv('education_districtwise.csv')
	education_districtwise = education_districtwise.dropna()

Now imagine that you are asked to collect the data on district literacy rates, and that you have limited time to do so. You can only survey 50 randomly chosen districts, instead of the 634 districts included in your original dataset. The goal of your research study is to estimate the mean literacy rate for all 634 districts based on your sample of 50 districts.You can use Python to simulate taking a random sample of 50 districts from your dataset. To do this, usepandas.DataFrame.sample(). The following arguments in the sample() function will help you simulate random sampling:

n: Refers to the desired sample size
replace: Indicates whether you are sampling with or without replacement
random_state: Refers to the seed of the random number


.. code-block:: python

	sampled_data = education_districtwise.sample(n=50, replace=True, random_state=31208)

Now that you have your random sample, use the mean function to compute the sample mean:


.. code-block:: python

	estimate1 = sampled_data['OVERALL_LI'].mean()


The sample mean for district literacy rate is about 74.22%. This is a point estimate of the population mean based on your random sample of 50 districts. Remember that the population mean is the literacy rate for all districts. Due to sampling variability, the sample mean is usually not exactly the same as the population mean.It should be noted that that the central limit theorem tells you that when the sample size is large enough, the sample mean approaches a normal distribution. And, as you sample more observations from a population, the sample mean gets closer to the population mean. The larger your sample size, the more accurate your estimate of the population mean is likely to be.


You can use Python to compute the mean of the sampling distribution with 10,000 samples:



.. code-block:: python

	estimate_list = []
	for i in range(10000):
    	    estimate_list.append(education_districtwise['OVERALL_LI'].sample(n=50, replace=True).mean())
	estimate_df = pd.DataFrame(data={'estimate': estimate_list})


Now we can compute the mean for the sampling distribution of 10,000 random samples:


.. code-block:: python

	mean_sample_means = estimate_df['estimate'].mean()



The mean of your sampling distribution is about 73.4%. Compare this with the population mean of your complete dataset:

.. code-block:: python

	population_mean = education_districtwise['OVERALL_LI'].mean()


The mean of your sampling distribution is essentially identical to the population mean, which is also about 73.4%.

To visualize the relationship between your sampling distribution of 10,000 estimates and the normal distribution, we can plot both at the same time:


.. code-block:: python

	plt.plot(x, p,'k', linewidth=2,color='b', label = 'normal curve from central limit theorem')
	plt.axvline(x=population_mean, color='g', linestyle = 'solid', label = 'population mean')
	plt.axvline(x=estimate1, color='r', linestyle = '--', label = 'sample mean of the first random sample')
	plt.axvline(x=mean_sample_means, color='b', linestyle = ':', label = 'mean of sample means of 10000 random samples')
	plt.title("Sampling distribution of sample mean")
	plt.xlabel('sample mean')
	plt.ylabel('density')
	plt.legend(bbox_to_anchor=(1.04,1))
	plt.show()


Here is the output graph:

.. figure:: PNG/25.png
   :align: center


Here are the main conclusions based on the above graph:

As the central limit theorem predicts, the histogram of the sampling distribution is well approximated by the normal distribution. The outline of the histogram closely follows the normal curve.
The mean of the sampling distribution, the blue dotted line, overlaps with the population mean, the green solid line. This shows that the two means are essentially equal to each other.
The sample mean of your first estimate of 50 districts, the red dashed line, is farther away from the center. This is due to sampling variability.




5.3. Probability distribution
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

First we need to import relevant libraries, packages, and modules. For this lab, you will need numpy, pandas, matplotlib.pyplot, statsmodels.api, and scipy:

.. code-block:: python

	import numpy as np
	import pandas as pd
	import matplotlib.pyplot as plt
	import statsmodels.api as sm
	from scipy import stats



In order to determine which type of probability distribution best fits data, calculate z-score. Here we use a new set of the air quality data. This subset is a .csv file named modified_c4_epa_air_quality.csv:


.. code-block:: python

	data = pd.read_csv("modified_c4_epa_air_quality.csv")




Now, we want to find out whether aqi_log fits a specific type of probability distribution. Create a histogram to visualize the distribution of aqi_log. Then, based on its shape, visually determine if it resembles a particular distribution:


.. code-block:: python

	data["aqi_log"].hist(color = 'b');

Here is the output: 

.. figure:: PNG/27.png
   :align: center



There is a slight right skew, but it still appears to be a bell shape. This shape suggests that the distribution of this data should be approximately normal.



According to the empirical rule states that, for every normal distribution:

1. 68% of the data fall within 1 standard deviation of the mean
2. 95% of the data fall within 2 standard deviations of the mean
3. 99.7% of the data fall within 3 standard deviations of the mean


First, define two variables to store the mean and standard deviation, respectively, for aqi_log:


.. code-block:: python

	mean_aqi_log = data["aqi_log"].mean()
	std_aqi_log = data["aqi_log"].std()
	print(mean_aqi_log)
	print(std_aqi_log)


Now, for example we can check the first part of the empirical rule: whether 68% of the aqi_log data falls within 1 standard deviation of the mean. To compute the actual percentage of the data that satisfies this criteria, define the lower limit (for example, 1 standard deviation below the mean) and the upper limit (for example, 1 standard deviation above the mean). 

.. code-block:: python

	lower_limit = mean_aqi_log - 1 * std_aqi_log
	Define variable for upper limit, 1 standard deviation above the mean.
	upper_limit = mean_aqi_log + 1 * std_aqi_log
	print(lower_limit, upper_limit)



Now we can compute the actual percentage of data that falls within 1 standard deviation of the mean:

.. code-block:: python

	((data["aqi_log"] >= lower_limit) & (data["aqi_log"] <= upper_limit)).mean() * 100

We can do the same thing for the second and third empirical rules. After doing this, here are the the results:

About 75.15% of the data falls within 1 standard deviation of the mean.
About 95.77% of the data falls within 2 standard deviation of the mean.
About 99.62% of the data falls within 3 standard deviations of the mean.

The 95.77% is very close to 95%, and the 99.62% is very close to 99.7%. The 75.15% is not as close to 68%, but relatively close. Overall, from applying the empirical rule, the data appears to be not exactly normal, but could be considered approximately normal.

The z-score is defined as: 

.. math:: 
  :name: eq.112

   z_{score}= \frac {x-\mu}{\sigma} 

Where :math:`x` , :math:`\mu` and :math:`\sigma` correspond to the raw data, population mean and standard deviation of the population respectively. 

Since z-score indicates the relative position of values (for instance, z-score measures how many standard deviations below or above the mean a data point is), it can be used to detect outliers. Z-score could be used to identify values that lie more than 3 standard deviations below or above the mean. These values may be considered outliers.We can compute the z-score for every aqi_log value. Then, add a column named z_score in the data to store those results:


.. code-block:: python

	data["z_score"] = stats.zscore(data["aqi_log"])

	# Display the first 3 rows to ensure that the new column was added.
	data.head(3)

Identify the parts of the data where aqi_log is above or below 3 standard deviations of the mean.


.. code-block:: python


	data[(data["z_score"] > 3) | (data["z_score"] < -3)]

Detecting outliers is important because they can reveal two important things, depending on the context: First, they can identify measurements that were taken incorrectly. Second, they can highlight parts of the data that can be focused on to make improvements.Z-score allows to identify potential outliers in the data.


5.4. Confidence intervals
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


In this section, we will work again with the air quality data in order to calculate the confidence interval. We start with importing the required packages and loading the data from the csv file:


.. note::

   For the purposes of your analysis, you can assume this data is randomly sampled from a larger population




.. code-block:: python


	aqi = pd.read_csv('c4_epa_air_quality.csv')
	import pandas as pd
	import numpy as np



We can find the number of each state in this data sheet:


.. code-block:: python


	print(aqi['state_name'].value_counts())



Now we want to extract the information for some desired states



.. code-block:: python


	print(aqi['state_name'].value_counts())


	# Create a list of desired states.
	rre_states = ['California','Florida','Michigan','Ohio','Pennsylvania','Texas']

	# Subset `aqi` to only consider these states.
	aqi_rre = aqi[aqi['state_name'].isin(rre_states)]

	# Find the mean aqi for each of the desired states.
	aqi_rre.groupby(['state_name']).agg({"aqi":"mean","state_name":"count"}) #alias as aqi_rre


We can make a box plot to visualize the distribution of the air quality index in these states using seaborn library:

.. code-block:: python


	import seaborn as sns
	sns.boxplot(x=aqi_rre["state_name"],y=aqi_rre["aqi"])



Here is the output:


.. figure:: PNG/28.png
   :align: center


We need to take 4 steps to calculate the confidence interval:

Recall the four-step process for constructing a confidence interval:

1. Identify a sample statistic.
2. Choose a confidence level.
3. Find the margin of error.
4. Calculate the interval.

First we need to calculate the mean AQI of the California state:


.. code-block:: python

	aqi_ca = aqi[aqi['state_name']=='California']
	sample_mean = aqi_ca['aqi'].mean()

We need to select a confidence level for the analysis. The most typical confidence level chosen is 95%;


.. code-block:: python

	confidence_level = 0.95

Next we need to calculate the margin of error. The margin of error = z * standard error, where z is the appropriate z-value for the given confidence level. The z value could be obtained using this table: 

..  csv-table:: Confidence Level vs Z score
   :widths: 5,5

   Confidence Level, Z score
   90%	,1.65
   95%	,1.96
   99%	,2.58


In addition, the standard error is calculated using this formula:


.. math:: 
  :name: eq.313

   Standard Error= \frac {S}{\sqrt{n}} 

Where :math:`S` and :math:`n` are standard deviation and size of the data. 


.. code-block:: python


	# Defining the z associated with the chosen confidence level.
	z_value = 1.96

	# Calculate the standard error.
	standard_error = aqi_ca['aqi'].std() / np.sqrt(aqi_ca.shape[0])


	# Calculate the margin of error.
	margin_of_error = standard_error * z_value
	print("margin of error:")


Finally, we can calculate the lower and upper bounds of the confidence interval which is the mean of the sample minus and plus the margin of error:


.. code-block:: python


	upper_ci_limit = sample_mean + margin_of_error
	lower_ci_limit = sample_mean - margin_of_error


There is also a workaround to calculate the confidence interval by using the spicy library: 


.. code-block:: python


	from scipy import stats
	stats.norm.interval(alpha=confidence_level, loc=sample_mean, scale=standard_error)

Where the ample_mean and standard_error should be calculated and given by the user in above line. 
Lastly, we can conclude that confidence interval at the 95% level of confidence from this **sample** data yielded [10.36 , 13.88] meaning that "given the observed sample AQI measurements, there is a 95% confidence that the **population** mean AQI for California was between 10.36 and 13.88.

.. note::

   It should be noted that by increasing the confidence level, the final calculated confidence interval will be expanded. For example by setting the confidence level at 99%, the confidence interval will be found equal to [9.80 , 14.43].



5.5. Hypothesis testing
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Now we want to construct a hypothesis test to know if the mean AQI in Los Angeles County is statistically different from the rest of California. For this purpose, we consider a 95% level of significance. As usual, we start by importing the required packages and loading the data:



.. code-block:: python


	import pandas as pd
	import numpy as np
	from scipy import stats
	aqi = pd.read_csv('c4_epa_air_quality.csv')


Here are the steps we should take for conducting hypothesis testing:

1. Formulate the null hypothesis and the alternative hypothesis.
2. Set the significance level.
3. Determine the appropriate test procedure.
4. Compute the p-value.
5. Making conclusion.


We want to know, within California, they want to know if the mean AQI in Los Angeles County is statistically different from the rest of California.


We can separate the data in California based on the county name (Los Angeles vs NOT Los Angeles):


.. code-block:: python


	ca_la = aqi[aqi['county_name']=='Los Angeles']
	ca_other = aqi[(aqi['state_name']=='California') & (aqi['county_name']!='Los Angeles')]



We can express the null and alternative hypotheses:

:math:`H_{0}`: There is no difference in the mean AQI between Los Angeles County and the rest of California.

:math:`H_{A}`:There is a difference in the mean AQI between Los Angeles County and the rest of California.


Next we set the confidence interval: 


.. code-block:: python

	significance_level = 0.95	


We want to compare the sample means between two independent samples. Therefore, you will utilize a two-sample ð‘¡-test:



.. code-block:: python

	stats.ttest_ind(a=ca_la['aqi'], b=ca_other['aqi'], equal_var=False)	


Here is the output: 

.. code-block:: python

	Ttest_indResult(statistic=2.1107010796372014, pvalue=0.049839056842410995)

According to the p-value (0.049) being less than 0.05 (as your confidence level is 95%), we can reject the null hypothesis. 

In the next step we want to know if New York has a lower AQI than Ohio or not. First we need to create two subsets of the data corresponding to each state:



.. code-block:: python

	ny = aqi[aqi['state_name']=='New York']
	ohio = aqi[aqi['state_name']=='Ohio']


We can express the null and alternative hypothesis as below: 

:math:`H_{0}`: The mean AQI of New York is greater than or equal to that of Ohio.

:math:`H_{A}`: The mean AQI of New York is below that of Ohio.

Again, we are comparing the sample means between two independent samples in one direction. Therefore, we will utilize a two-sample ð‘¡-test:


.. code-block:: python


	tstat, pvalue = stats.ttest_ind(a=ny['aqi'], b=ohio['aqi'], alternative='less')
	print(tstat)
	print(pvalue)


Here is the output: 


.. code-block:: python

	-1.891850434703295
	0.03654034300840755

As the p-value (0.030) is less than 0.05 (as your confidence level is 95%) and a t-statistic < 0 (-2.02), we can reject the null hypothesis. In other words, we can conclude with 95% confidence that New York has a lower mean AQI than Ohio.


In the third example, we want to know if the AQI of the Michigan state is greater than 10 or not. First we need to extract the information for the Michigan state: 


.. code-block:: python

	michigan = aqi[aqi['state_name']=='Michigan']



Then we state the null and alternative hypothesis

:math:`H_{0}`:The mean AQI of Michigan is less than or equal to 10.

:math:`H_{A}`:The mean AQI of Michigan is greater than 10.


This is a different situation as we are comparing one sample mean relative to a particular value in one direction. Therefore, we will utilize a one-sample ð‘¡-test.


.. code-block:: python

	tstat, pvalue = stats.ttest_1samp(michigan['aqi'], 10, alternative='greater')
	print(tstat)
	print(pvalue)


This is the output:


.. code-block:: python

	-1.7395913343286131
	0.9399405193140109

With a p-value than 0.05 (as your confidence level is 95%) and a t-statistic < 0 (-1.73), we fail to reject the null hypothesis. Therefore, you cannot conclude with 95% confidence that Michigan's mean AQI is below 10.


.. note::

   The difference between the z score and t score is that when using the z score, the standard deviation of the population is known while when using the t score, it is not. Instead we use the standard deviation of the sample in the formula.



.. math:: 
  :name: eq.114

   t_{score}= \frac {\bar{X}-\mu}{\sigma} 

Where :math:`\bar{X}` , :math:`\mu` and :math:`\sigma` correspond to the sample mean, population mean and standard deviation of the sample respectively. 




